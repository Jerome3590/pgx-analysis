{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DTW Feature Engineering – Cohort 2 (POLYPHARMACY_ED, non_opioid_ed), Configurable Age Band\n",
        "\n",
        "This notebook configures DTW-based trajectory features for `non_opioid_ed` (polypharmacy ED)\n",
        "across configurable older age bands (e.g. **65-74**, **75-84**, **85-94**) for the TRAIN window (2016–2018).\n",
        "\n",
        "- **Source events**: `model_data/cohort_name=non_opioid_ed/age_band={AGE_BAND}/model_events.parquet`\n",
        "- **High-signal activity alphabet**: FP-Growth TRAIN target-only itemsets\n",
        "  `4_fpgrowth_analysis/outputs/non_opioid_ed/target/{AGE_BAND_FNAME}/train/*_itemsets_target_only.json`.\n",
        "- **Activities**: `DRUG:<code>`, `ICD:<code>`, `CPT:<code>` from `drug_name`, all ICD columns, and `procedure_code`,\n",
        "  with an emphasis on **DRUG:** trajectories for polypharmacy burden.\n",
        "- **Outputs**: per-patient DTW distance features\n",
        "  `non_opioid_ed_{AGE_BAND_FNAME}_train_target_dtw_features.csv` saved under\n",
        "  `6_dtw_analysis/outputs/non_opioid_ed/{AGE_BAND_FNAME}/features/` (and optionally uploaded to S3).\n",
        "\n",
        "For each age band we:\n",
        "- Build per-patient ordered DRUG/ICD/CPT sequences (target-only, filtered by FP-Growth itemsets).\n",
        "- Map activities to integer IDs.\n",
        "- Compute DTW distances to a small set of prototype trajectories.\n",
        "- Export a **patient-level DTW feature table** aligned with the final modeling pipeline.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Config for Cohort 2 (POLYPHARMACY_ED, non_opioid_ed), configurable age band ----\n",
        "\n",
        "from pathlib import Path\n",
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "PROJECT_ROOT = Path.cwd().resolve()  # assume you launch from project root\n",
        "\n",
        "COHORT_NAME = \"non_opioid_ed\"\n",
        "\n",
        "# Valid polypharmacy age bands (cohorts 6–8)\n",
        "VALID_AGE_BANDS = [\"65-74\", \"75-84\", \"85-94\"]\n",
        "AGE_BAND = \"65-74\"  # <-- change this to run for another age band\n",
        "\n",
        "if AGE_BAND not in VALID_AGE_BANDS:\n",
        "    raise ValueError(f\"Invalid AGE_BAND: {AGE_BAND}. Choose one of: {VALID_AGE_BANDS}\")\n",
        "\n",
        "TRAIN_YEARS = [2016, 2017, 2018]\n",
        "AGE_BAND_FNAME = AGE_BAND.replace(\"-\", \"_\")\n",
        "\n",
        "MODEL_DATA_PATH = (\n",
        "    PROJECT_ROOT\n",
        "    / \"model_data\"\n",
        "    / f\"cohort_name={COHORT_NAME}\"\n",
        "    / f\"age_band={AGE_BAND}\"\n",
        "    / \"model_events.parquet\"\n",
        ")\n",
        "\n",
        "FPGROWTH_ROOT = PROJECT_ROOT / \"4_fpgrowth_analysis\" / \"outputs\" / COHORT_NAME\n",
        "TARGET_DIR_TRAIN = FPGROWTH_ROOT / \"target\" / AGE_BAND_FNAME / \"train\"\n",
        "\n",
        "ITEMSETS_DRUG_PATH = TARGET_DIR_TRAIN / \"drug_name_itemsets_target_only.json\"\n",
        "ITEMSETS_ICD_PATH = TARGET_DIR_TRAIN / \"icd_code_itemsets_target_only.json\"\n",
        "ITEMSETS_MEDICAL_PATH = TARGET_DIR_TRAIN / \"medical_code_itemsets_target_only.json\"\n",
        "\n",
        "print(\"Project root:\", PROJECT_ROOT)\n",
        "print(\"Cohort:\", COHORT_NAME)\n",
        "print(\"Age band:\", AGE_BAND)\n",
        "print(\"Model data path:\", MODEL_DATA_PATH)\n",
        "print(\"FP-Growth target TRAIN dir:\", TARGET_DIR_TRAIN)\n",
        "\n",
        "if not MODEL_DATA_PATH.exists():\n",
        "    raise FileNotFoundError(f\"model_data parquet not found: {MODEL_DATA_PATH}\")\n",
        "\n",
        "DTW_OUTPUT_ROOT = PROJECT_ROOT / \"6_dtw_analysis\" / \"outputs\" / COHORT_NAME / AGE_BAND_FNAME\n",
        "DTW_FEATURE_ROOT = DTW_OUTPUT_ROOT / \"features\"\n",
        "DTW_FEATURE_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"DTW output root:\", DTW_OUTPUT_ROOT)\n",
        "print(\"DTW feature root:\", DTW_FEATURE_ROOT)\n",
        "\n",
        "\n",
        "def save_dtw_csv(df: pd.DataFrame, filename: str, upload_to_s3: bool = False) -> Path:\n",
        "    out_path = DTW_FEATURE_ROOT / filename\n",
        "    df.to_csv(out_path, index=False)\n",
        "    print(f\"[DTW] Saved {len(df)} rows to {out_path}\")\n",
        "\n",
        "    if upload_to_s3:\n",
        "        s3_key = f\"gold/dtw/{COHORT_NAME}/{AGE_BAND}/{filename}\"\n",
        "        s3_uri = f\"s3://pgxdatalake/{s3_key}\"\n",
        "        cmd = f\"aws s3 cp \\\"{out_path}\\\" \\\"{s3_uri}\\\"\"\n",
        "        print(\"[DTW] Uploading to S3 with command:\\n  \", cmd)\n",
        "        import os\n",
        "        os.system(cmd)\n",
        "\n",
        "    return out_path\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Load model_data and build target patient activity sequences ----\n",
        "\n",
        "import duckdb\n",
        "\n",
        "con = duckdb.connect()\n",
        "\n",
        "query = f\"\"\"\n",
        "SELECT *\n",
        "FROM read_parquet('{MODEL_DATA_PATH}')\n",
        "WHERE event_year IN ({', '.join(str(y) for y in TRAIN_YEARS)})\n",
        "\"\"\"\n",
        "\n",
        "pgx_df = con.execute(query).df()\n",
        "con.close()\n",
        "\n",
        "print(\"Loaded\", len(pgx_df), \"events from model_data for\", COHORT_NAME, \"age_band=\", AGE_BAND,\n",
        "      \"years\", TRAIN_YEARS)\n",
        "\n",
        "# Target-only for DTW trajectories\n",
        "pgx_df_target1 = pgx_df[pgx_df[\"target\"] == 1].copy()\n",
        "print(\"Target=1 rows:\", len(pgx_df_target1))\n",
        "\n",
        "# Build allowed_codes from FP-Growth TRAIN target-only itemsets (drug, icd, medical_code)\n",
        "allowed_codes: set[str] = set()\n",
        "\n",
        "for path in [ITEMSETS_DRUG_PATH, ITEMSETS_ICD_PATH, ITEMSETS_MEDICAL_PATH]:\n",
        "    if path.exists():\n",
        "        with open(path, \"r\") as f:\n",
        "            data = json.load(f)\n",
        "        for row in data:\n",
        "            for code in row.get(\"itemsets\", []):\n",
        "                allowed_codes.add(code)\n",
        "        print(f\"Loaded {len(data)} itemsets from {path.name}\")\n",
        "    else:\n",
        "        print(f\"[WARN] Itemsets file not found: {path}\")\n",
        "\n",
        "print(\"Total allowed codes from itemsets:\", len(allowed_codes))\n",
        "\n",
        "activity_rows: list[tuple[str, str, str]] = []\n",
        "\n",
        "for _, row in pgx_df_target1.iterrows():\n",
        "    pid = row[\"mi_person_key\"]\n",
        "    event_date = row[\"event_date\"]\n",
        "\n",
        "    # Drug (primary focus for polypharmacy)\n",
        "    drug = row.get(\"drug_name\")\n",
        "    if isinstance(drug, str) and drug not in (\"\", \"NA\") and drug in allowed_codes:\n",
        "        activity_rows.append((pid, event_date, f\"DRUG:{drug}\"))\n",
        "\n",
        "    # ICDs and CPT as contextual activities\n",
        "    for col in [\n",
        "        \"primary_icd_diagnosis_code\",\n",
        "        \"two_icd_diagnosis_code\",\n",
        "        \"three_icd_diagnosis_code\",\n",
        "        \"four_icd_diagnosis_code\",\n",
        "        \"five_icd_diagnosis_code\",\n",
        "        \"six_icd_diagnosis_code\",\n",
        "        \"seven_icd_diagnosis_code\",\n",
        "        \"eight_icd_diagnosis_code\",\n",
        "        \"nine_icd_diagnosis_code\",\n",
        "        \"ten_icd_diagnosis_code\",\n",
        "    ]:\n",
        "        code = row.get(col)\n",
        "        if isinstance(code, str) and code not in (\"\", \"NA\") and code in allowed_codes:\n",
        "            activity_rows.append((pid, event_date, f\"ICD:{code}\"))\n",
        "\n",
        "    proc = row.get(\"procedure_code\")\n",
        "    if isinstance(proc, str) and proc not in (\"\", \"NA\") and proc in allowed_codes:\n",
        "        activity_rows.append((pid, event_date, f\"CPT:{proc}\"))\n",
        "\n",
        "activity_df = pd.DataFrame(activity_rows, columns=[\"mi_person_key\", \"event_date\", \"activity\"])\n",
        "activity_df[\"event_date\"] = pd.to_datetime(activity_df[\"event_date\"])\n",
        "\n",
        "print(\"Activity table shape:\", activity_df.shape)\n",
        "\n",
        "activity_df = activity_df.sort_values([\"mi_person_key\", \"event_date\"])\n",
        "\n",
        "sequences = (\n",
        "    activity_df\n",
        "    .groupby(\"mi_person_key\")[\"activity\"]\n",
        "    .apply(list)\n",
        "    .reset_index()\n",
        "    .rename(columns={\"activity\": \"activity_sequence\"})\n",
        ")\n",
        "\n",
        "print(\"Built\", len(sequences), \"patient sequences for DTW\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- DTW distance computation to prototype trajectories ----\n",
        "\n",
        "from typing import List, Dict\n",
        "\n",
        "unique_activities = sorted({a for seq in sequences[\"activity_sequence\"] for a in seq})\n",
        "activity_to_id: Dict[str, int] = {a: i for i, a in enumerate(unique_activities)}\n",
        "\n",
        "print(\"Unique activities:\", len(unique_activities))\n",
        "\n",
        "int_sequences: Dict[str, List[int]] = {}\n",
        "for _, row in sequences.iterrows():\n",
        "    pid = row[\"mi_person_key\"]\n",
        "    seq = [activity_to_id[a] for a in row[\"activity_sequence\"]]\n",
        "    int_sequences[pid] = seq\n",
        "\n",
        "\n",
        "def dtw_distance(s1: List[int], s2: List[int]) -> float:\n",
        "    n, m = len(s1), len(s2)\n",
        "    if n == 0 or m == 0:\n",
        "        return math.inf\n",
        "    dp = np.full((n + 1, m + 1), np.inf)\n",
        "    dp[0, 0] = 0.0\n",
        "    for i in range(1, n + 1):\n",
        "        for j in range(1, m + 1):\n",
        "            cost = 0.0 if s1[i - 1] == s2[j - 1] else 1.0\n",
        "            dp[i, j] = cost + min(dp[i - 1, j], dp[i, j - 1], dp[i - 1, j - 1])\n",
        "    return float(dp[n, m])\n",
        "\n",
        "\n",
        "MAX_PROTOTYPES = 20\n",
        "prototype_ids: List[str] = []\n",
        "for pid, seq in int_sequences.items():\n",
        "    if seq:\n",
        "        prototype_ids.append(pid)\n",
        "    if len(prototype_ids) >= MAX_PROTOTYPES:\n",
        "        break\n",
        "\n",
        "print(\"Selected\", len(prototype_ids), \"prototype patients for DTW features\")\n",
        "\n",
        "feature_rows: List[Dict[str, float]] = []\n",
        "\n",
        "for pid, seq in int_sequences.items():\n",
        "    row: Dict[str, float] = {\"mi_person_key\": pid}\n",
        "    for k, proto_pid in enumerate(prototype_ids, start=1):\n",
        "        d = dtw_distance(seq, int_sequences[proto_pid])\n",
        "        row[f\"dtw_dist_proto_{k}\"] = d\n",
        "    feature_rows.append(row)\n",
        "\n",
        "features_df = pd.DataFrame(feature_rows)\n",
        "print(\"DTW feature table shape:\", features_df.shape)\n",
        "\n",
        "out_filename = f\"{COHORT_NAME}_{AGE_BAND_FNAME}_train_target_dtw_features.csv\"\n",
        "save_dtw_csv(features_df, out_filename, upload_to_s3=False)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
