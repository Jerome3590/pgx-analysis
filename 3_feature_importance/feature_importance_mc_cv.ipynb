{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59bb209f",
   "metadata": {},
   "source": [
    "# Feature Importance with Monte Carlo Cross-Validation\n",
    "\n",
    "**Purpose:** Calculate scaled feature importance using CatBoost and Random Forest  \n",
    "**Method:** Normalized feature importance scaled by MC-CV Recall scores  \n",
    "**Based on:** [R Example](https://github.com/Jerome3590/phts/blob/main/graft-loss/feature_importance/replicate_20_features_MC_CV.R)  \n",
    "**Updated:** November 2025  \n",
    "**Hardware:** Optimized for EC2 (32 cores, 1TB RAM)  \n",
    "**Validation:** Proper evaluation on unseen test data\n",
    "\n",
    "## Key Features\n",
    "\n",
    "‚úÖ **Monte Carlo Cross-Validation** ‚Äì up to 1000 random train/test splits (100-split runs used for faster iteration)  \n",
    "‚úÖ **Stratified Sampling** - Maintains target distribution  \n",
    "‚úÖ **Parallel Processing** - Fast execution with furrr/future (‚âà30 workers)  \n",
    "‚úÖ **95% Confidence Intervals** - Narrow, precise estimates (tighter with more splits)  \n",
    "‚úÖ **Multiple Models** - CatBoost (R) and Random Forest (R)  \n",
    "\n",
    "## Methodology\n",
    "\n",
    "This notebook implements the feature selection methodology:\n",
    "\n",
    "1. Load cohort data from parquet files (same as FP-Growth notebook)\n",
    "2. Create patient-level features (one-hot encoding of items)\n",
    "3. For each model type:\n",
    "   - Create 100‚Äì1000 stratified train/test splits\n",
    "   - Train model on training set\n",
    "   - Evaluate Recall on unseen test set\n",
    "   - Extract feature importance\n",
    "   - Aggregate results across splits\n",
    "4. Normalize and scale feature importance by MC-CV Recall\n",
    "5. Aggregate across models\n",
    "6. Extract top features\n",
    "\n",
    "## Expected Runtime\n",
    "\n",
    "- **100 splits (current default):**\n",
    "  - Local (4 cores): ~2‚Äì4 hours\n",
    "  - Workstation (16 cores): ~1‚Äì2 hours\n",
    "  - EC2 (32 cores, 1TB RAM): ~1‚Äì2 hours ‚úÖ **RECOMMENDED FOR DEVELOPMENT**\n",
    "- **1000 splits (extended / publication-level):**\n",
    "  - Local (4 cores): 8‚Äì12+ hours\n",
    "  - Workstation (16 cores): ~8‚Äì16 hours\n",
    "  - EC2 (32 cores, 1TB RAM): ~10‚Äì20 hours ‚úÖ **RECOMMENDED FOR FINAL RESULTS**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eb9c0a",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "Load required packages and configure parallel processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0617449b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Check R version\n",
    "R.version.string\n",
    "\n",
    "# Load required packages\n",
    "suppressPackageStartupMessages({\n",
    "  library(here)\n",
    "  library(dplyr)\n",
    "  library(readr)\n",
    "  library(tidyr)\n",
    "  library(tibble)\n",
    "  library(purrr)\n",
    "  library(catboost)\n",
    "  library(randomForest)\n",
    "  library(rsample)    # For MC-CV\n",
    "  library(furrr)      # For parallel processing\n",
    "  library(future)     # For parallel backend\n",
    "  library(progressr)  # For progress bars\n",
    "  library(duckdb)     # For loading parquet files\n",
    "  library(DBI)        # Database interface for DuckDB\n",
    "})\n",
    "\n",
    "cat(\"‚úì All packages loaded successfully\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785bdbc1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEBUG/TEST MODE - Quick testing before full run\n",
    "# ============================================================\n",
    "# Set DEBUG_MODE = TRUE for quick testing (5 splits, ~2-5 min)\n",
    "# Set DEBUG_MODE = FALSE for full analysis (100 splits, ~1-2 hours on EC2)\n",
    "\n",
    "DEBUG_MODE <- TRUE  # Change to TRUE for quick test\n",
    "\n",
    "if (DEBUG_MODE) {\n",
    "  cat(\"\\n\")\n",
    "  cat(\"‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\\n\")\n",
    "  cat(\"‚ïë                    üîç DEBUG MODE ENABLED                       ‚ïë\\n\")\n",
    "  cat(\"‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\\n\")\n",
    "  cat(\"\\n\")\n",
    "  cat(\"Quick test configuration:\\n\")\n",
    "  cat(\"  ‚Ä¢ MC-CV Splits: 5 (instead of 100)\\n\")\n",
    "  cat(\"  ‚Ä¢ Expected time: 2-5 minutes\\n\")\n",
    "  cat(\"  ‚Ä¢ Purpose: Verify everything works before full run\\n\")\n",
    "  cat(\"\\n\")\n",
    "  cat(\"To run full analysis, set DEBUG_MODE = FALSE\\n\")\n",
    "  cat(\"\\n\")\n",
    "}\n",
    "\n",
    "# Configuration\n",
    "# NOTE: Target definition differs by cohort (already baked into cohort data via is_target_case):\n",
    "#   - \"opioid_ed\": Target cases = patients with F1120/opioid ICD codes (any of 10 ICD columns)\n",
    "#   - \"non_opioid_ed\": Target cases = patients with HCG ED visits (P51/O11/P33) WITHOUT opioid codes\n",
    "# Controls (is_target_case=0) are sampled to maintain 5:1 ratio in both cohorts\n",
    "COHORT_NAME <- \"opioid_ed\"  # Options: \"opioid_ed\" or \"non_opioid_ed\"\n",
    "AGE_BAND <- \"25-44\"         # Change as needed\n",
    "EVENT_YEAR <- 2016          # Change as needed\n",
    "\n",
    "N_SPLITS <- if (DEBUG_MODE) 5 else 100  # MC-CV splits (5 for debug, 100 for development, 1000 for production)\n",
    "TEST_SIZE <- 0.2             # Test set proportion (20%)\n",
    "TRAIN_PROP <- 1 - TEST_SIZE  # Training proportion (80%)\n",
    "\n",
    "# Scaling metric for feature importance\n",
    "# Options: \"recall\" (default) or \"logloss\"\n",
    "# - Recall: Higher is better (0-1), good for imbalanced classes, focuses on finding positives\n",
    "# - LogLoss: Lower is better, measures probability calibration, penalizes overconfident errors\n",
    "#   (will be inverted: 1/logloss for scaling, so higher = better)\n",
    "SCALING_METRIC <- \"recall\"  # Change to \"logloss\" if preferred\n",
    "\n",
    "# Model parameters\n",
    "MODEL_PARAMS <- list(\n",
    "  catboost = list(\n",
    "    iterations = 100,\n",
    "    learning_rate = 0.1,\n",
    "    depth = 6,\n",
    "    verbose = 0L,  # Turn off CatBoost logging (0L = integer 0)\n",
    "    random_seed = 42\n",
    "  ),\n",
    "  random_forest = list(\n",
    "    ntree = 100,\n",
    "    mtry = NULL,  # Will be set to sqrt(n_features)\n",
    "    nodesize = 1,\n",
    "    maxnodes = NULL\n",
    "  )\n",
    ")\n",
    "\n",
    "# Set up parallel processing\n",
    "# EC2 optimization: Use 30 out of 32 cores (leave 2 for system)\n",
    "N_WORKERS <- as.integer(Sys.getenv(\"N_WORKERS\", \"0\"))\n",
    "if (N_WORKERS < 1) {\n",
    "  # Auto-detect: use all cores minus 2 for system\n",
    "  total_cores <- parallel::detectCores()\n",
    "  N_WORKERS <- max(1, total_cores - 2)\n",
    "  cat(sprintf(\"Auto-detected %d cores, using %d workers\\n\", total_cores, N_WORKERS))\n",
    "}\n",
    "cat(sprintf(\"Setting up parallel processing with %d workers...\\n\", N_WORKERS))\n",
    "\n",
    "# Increase future.globals.maxSize for large MC-CV splits object\n",
    "# With 1TB RAM on EC2, we can handle large transfers\n",
    "# Note: MC-CV splits and data matrices can be very large (30+ GB)\n",
    "# Increase limit to accommodate large feature matrices (19,586 features √ó 31,146 patients)\n",
    "options(future.globals.maxSize = 97 * 1024^3)  # 97 GB limit (increased from 20 GB)\n",
    "cat(\"Set future.globals.maxSize to 97 GB\\n\")\n",
    "\n",
    "plan(multisession, workers = N_WORKERS)\n",
    "\n",
    "# Output directory\n",
    "output_dir <- here(\"outputs\")\n",
    "dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)\n",
    "\n",
    "cat(\"Output directory:\", output_dir, \"\\n\")\n",
    "cat(sprintf(\"MC-CV Configuration: %d splits, %.0f/%.0f train/test split\\n\", \n",
    "            N_SPLITS, TRAIN_PROP * 100, TEST_SIZE * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cde83f",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "Load cohort data from parquet files (same logic as FP-Growth notebook).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f80186",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Determine local data path (same as FP-Growth)\n",
    "LOCAL_DATA_PATH <- Sys.getenv(\"LOCAL_DATA_PATH\", \"/mnt/nvme/cohorts\")\n",
    "if (!dir.exists(LOCAL_DATA_PATH)) {\n",
    "  # Try Windows path\n",
    "  LOCAL_DATA_PATH <- Sys.getenv(\"LOCAL_DATA_PATH\", \"C:/Projects/pgx-analysis/data/gold/cohorts_F1120\")\n",
    "}\n",
    "\n",
    "parquet_file <- file.path(LOCAL_DATA_PATH, \n",
    "                          paste0(\"cohort_name=\", COHORT_NAME),\n",
    "                          paste0(\"event_year=\", EVENT_YEAR),\n",
    "                          paste0(\"age_band=\", AGE_BAND),\n",
    "                          \"cohort.parquet\")\n",
    "\n",
    "if (!file.exists(parquet_file)) {\n",
    "  stop(sprintf(\"Cohort file not found: %s\\nPlease check LOCAL_DATA_PATH and file structure.\", parquet_file))\n",
    "}\n",
    "\n",
    "cat(sprintf(\"Loading from: %s\\n\", parquet_file))\n",
    "\n",
    "# Load using DuckDB\n",
    "con <- dbConnect(duckdb::duckdb(), dbdir = \":memory:\")\n",
    "\n",
    "# Load cohort data (same columns as FP-Growth notebook)\n",
    "# NOTE: Use is_target_case as target variable (target column is hardcoded to 1 in cohort SQL)\n",
    "# is_target_case definition depends on COHORT_NAME:\n",
    "#   - opioid_ed: 1 = patients with opioid ICD codes (F1120, etc.), 0 = controls\n",
    "#   - non_opioid_ed: 1 = patients with HCG ED visits (no opioid codes), 0 = controls\n",
    "query <- sprintf(\"\n",
    "  SELECT \n",
    "    mi_person_key,\n",
    "    is_target_case as target,  -- Use is_target_case: 1=target case, 0=control\n",
    "    drug_name,\n",
    "    primary_icd_diagnosis_code,\n",
    "    two_icd_diagnosis_code,\n",
    "    three_icd_diagnosis_code,\n",
    "    four_icd_diagnosis_code,\n",
    "    five_icd_diagnosis_code,\n",
    "    procedure_code,\n",
    "    event_type\n",
    "  FROM read_parquet('%s')\n",
    "\", parquet_file)\n",
    "\n",
    "cohort_data <- dbGetQuery(con, query)\n",
    "dbDisconnect(con)\n",
    "\n",
    "cat(sprintf(\"Loaded %d event-level records\\n\", nrow(cohort_data)))\n",
    "cat(sprintf(\"Unique patients: %d\\n\", length(unique(cohort_data$mi_person_key))))\n",
    "\n",
    "# Print event type distribution\n",
    "cat(\"\\nEvent type distribution:\\n\")\n",
    "event_dist <- cohort_data %>%\n",
    "  count(event_type) %>%\n",
    "  mutate(pct = 100 * n / sum(n))\n",
    "for (i in 1:nrow(event_dist)) {\n",
    "  cat(sprintf(\"  %s: %d (%.1f%%)\\n\", event_dist$event_type[i], event_dist$n[i], event_dist$pct[i]))\n",
    "}\n",
    "\n",
    "# Print target distribution (at event level)\n",
    "cat(\"\\nTarget distribution (event-level):\\n\")\n",
    "target_dist <- cohort_data %>%\n",
    "  count(target) %>%\n",
    "  mutate(pct = 100 * n / sum(n))\n",
    "for (i in 1:nrow(target_dist)) {\n",
    "  cat(sprintf(\"  Target %d: %d events (%.1f%%)\\n\", target_dist$target[i], target_dist$n[i], target_dist$pct[i]))\n",
    "}\n",
    "\n",
    "# Print target distribution (patient-level)\n",
    "cat(\"\\nTarget distribution (patient-level):\\n\")\n",
    "patient_target_dist <- cohort_data %>%\n",
    "  select(mi_person_key, target) %>%\n",
    "  distinct() %>%\n",
    "  count(target) %>%\n",
    "  mutate(pct = 100 * n / sum(n))\n",
    "for (i in 1:nrow(patient_target_dist)) {\n",
    "  if (is.na(patient_target_dist$target[i])) {\n",
    "    cat(sprintf(\"  Target NA: %d patients (%.1f%%) ‚ö†Ô∏è  ISSUE: NULL is_target_case in source data\\n\", \n",
    "                patient_target_dist$n[i], patient_target_dist$pct[i]))\n",
    "  } else {\n",
    "    cat(sprintf(\"  Target %d: %d patients (%.1f%%)\\n\", \n",
    "                patient_target_dist$target[i], patient_target_dist$n[i], patient_target_dist$pct[i]))\n",
    "  }\n",
    "}\n",
    "\n",
    "# Check for patients with inconsistent target values across events\n",
    "cat(\"\\nChecking for patients with inconsistent target values:\\n\")\n",
    "inconsistent_patients <- cohort_data %>%\n",
    "  select(mi_person_key, target) %>%\n",
    "  distinct() %>%\n",
    "  group_by(mi_person_key) %>%\n",
    "  summarise(n_unique_targets = n_distinct(target, na.rm = FALSE), .groups = 'drop') %>%\n",
    "  filter(n_unique_targets > 1)\n",
    "\n",
    "if (nrow(inconsistent_patients) > 0) {\n",
    "  cat(sprintf(\"  ‚ö†Ô∏è  WARNING: %d patients have inconsistent target values across events!\\n\", \n",
    "              nrow(inconsistent_patients)))\n",
    "  cat(\"  This suggests is_target_case is calculated per-event instead of per-patient.\\n\")\n",
    "  cat(\"  Using first() value per patient as workaround.\\n\")\n",
    "} else {\n",
    "  cat(\"  ‚úì No inconsistencies found\\n\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853059a9",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "Create patient-level features with categorical factor columns for CatBoost.\n",
    "\n",
    "**Approach:**\n",
    "- Create feature columns where each column represents an item (drug, ICD code, CPT code)\n",
    "- Each column is a factor with levels based on the actual categorical values (item names)\n",
    "- Target remains binary (0/1)\n",
    "- For Random Forest: use numeric binary (0/1) format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a74527",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Extract all unique items per patient\n",
    "cat(\"\\nCreating patient-level features...\\n\")\n",
    "\n",
    "patient_items <- cohort_data %>%\n",
    "  # Drug names (pharmacy events)\n",
    "  filter(!is.na(drug_name) & drug_name != \"\" & event_type == \"pharmacy\") %>%\n",
    "  select(mi_person_key, item = drug_name) %>%\n",
    "  # ICD codes (medical events) - all 5 columns\n",
    "  bind_rows(\n",
    "    cohort_data %>%\n",
    "      filter(event_type == \"medical\") %>%\n",
    "      select(mi_person_key, item = primary_icd_diagnosis_code) %>%\n",
    "      filter(!is.na(item) & item != \"\"),\n",
    "    cohort_data %>%\n",
    "      filter(event_type == \"medical\") %>%\n",
    "      select(mi_person_key, item = two_icd_diagnosis_code) %>%\n",
    "      filter(!is.na(item) & item != \"\"),\n",
    "    cohort_data %>%\n",
    "      filter(event_type == \"medical\") %>%\n",
    "      select(mi_person_key, item = three_icd_diagnosis_code) %>%\n",
    "      filter(!is.na(item) & item != \"\"),\n",
    "    cohort_data %>%\n",
    "      filter(event_type == \"medical\") %>%\n",
    "      select(mi_person_key, item = four_icd_diagnosis_code) %>%\n",
    "      filter(!is.na(item) & item != \"\"),\n",
    "    cohort_data %>%\n",
    "      filter(event_type == \"medical\") %>%\n",
    "      select(mi_person_key, item = five_icd_diagnosis_code) %>%\n",
    "      filter(!is.na(item) & item != \"\")\n",
    "  ) %>%\n",
    "  # CPT codes (medical events)\n",
    "  bind_rows(\n",
    "    cohort_data %>%\n",
    "      filter(!is.na(procedure_code) & procedure_code != \"\" & event_type == \"medical\") %>%\n",
    "      select(mi_person_key, item = procedure_code)\n",
    "  ) %>%\n",
    "  distinct() %>%\n",
    "  filter(!is.na(item) & item != \"\")\n",
    "\n",
    "cat(sprintf(\"Extracted %d unique patient-item pairs\\n\", nrow(patient_items)))\n",
    "cat(sprintf(\"Unique items: %d\\n\", length(unique(patient_items$item))))\n",
    "\n",
    "# Get target per patient\n",
    "patient_targets <- cohort_data %>%\n",
    "  select(mi_person_key, target) %>%\n",
    "  distinct() %>%\n",
    "  group_by(mi_person_key) %>%\n",
    "  summarise(target = first(target), .groups = 'drop')\n",
    "\n",
    "# Create feature matrix (one column per item)\n",
    "# For CatBoost: Use actual item names as categorical values\n",
    "# For Random Forest: Use binary 0/1\n",
    "\n",
    "cat(\"\\nCreating feature matrix...\\n\")\n",
    "\n",
    "# Get all unique items to create columns\n",
    "all_unique_items <- sort(unique(patient_items$item))\n",
    "cat(sprintf(\"Creating %d feature columns (one per unique item)\\n\", length(all_unique_items)))\n",
    "\n",
    "# FOR CATBOOST: Create feature matrix where each column represents an item\n",
    "# Value is the item name itself (categorical), or NA if patient doesn't have it\n",
    "cat(\"\\nCreating CatBoost format (item names as categorical values)...\\n\")\n",
    "feature_matrix_catboost <- patient_items %>%\n",
    "  pivot_wider(\n",
    "    id_cols = mi_person_key,\n",
    "    names_from = item,\n",
    "    values_from = item,  # Use item name itself as value (not 0/1)\n",
    "    values_fill = NA_character_,  # NA if patient doesn't have the item\n",
    "    names_prefix = \"item_\"\n",
    "  ) %>%\n",
    "  left_join(patient_targets, by = \"mi_person_key\")\n",
    "\n",
    "# Validate join - check if target column has values\n",
    "cat(\"\\nValidating feature matrix join:\\n\")\n",
    "cat(sprintf(\"  feature_matrix_catboost rows: %d\\n\", nrow(feature_matrix_catboost)))\n",
    "cat(sprintf(\"  Target column present: %s\\n\", \"target\" %in% names(feature_matrix_catboost)))\n",
    "if (\"target\" %in% names(feature_matrix_catboost)) {\n",
    "  cat(sprintf(\"  Target NAs: %d (%.1f%%)\\n\", \n",
    "              sum(is.na(feature_matrix_catboost$target)), \n",
    "              100 * mean(is.na(feature_matrix_catboost$target))))\n",
    "  cat(sprintf(\"  Target positives: %d (%.1f%%)\\n\", \n",
    "              sum(feature_matrix_catboost$target == 1, na.rm = TRUE),\n",
    "              100 * mean(feature_matrix_catboost$target == 1, na.rm = TRUE)))\n",
    "  cat(sprintf(\"  Target negatives: %d (%.1f%%)\\n\", \n",
    "              sum(feature_matrix_catboost$target == 0, na.rm = TRUE),\n",
    "              100 * mean(feature_matrix_catboost$target == 0, na.rm = TRUE)))\n",
    "  \n",
    "  # Check for patients missing from patient_targets\n",
    "  missing_targets <- feature_matrix_catboost %>%\n",
    "    filter(is.na(target)) %>%\n",
    "    select(mi_person_key) %>%\n",
    "    distinct()\n",
    "  if (nrow(missing_targets) > 0) {\n",
    "    cat(sprintf(\"  WARNING: %d patients missing target values\\n\", nrow(missing_targets)))\n",
    "  }\n",
    "}\n",
    "\n",
    "# FOR CATBOOST: Convert ALL feature columns to factors with actual item names as levels\n",
    "cat(\"\\nCreating CatBoost format (categorical factors with item names as levels)...\\n\")\n",
    "data_catboost <- feature_matrix_catboost %>%\n",
    "  select(-mi_person_key) %>%\n",
    "  # Convert ALL feature columns (except target) to factors\n",
    "  # Each column has levels: NA (patient doesn't have item) or the item name itself\n",
    "  mutate(across(-target, ~ as.factor(.x)))\n",
    "\n",
    "y_catboost <- data_catboost$target\n",
    "X_catboost <- data_catboost %>% select(-target)\n",
    "\n",
    "cat(sprintf(\"CatBoost format:\\n\"))\n",
    "cat(sprintf(\"  Patients: %d\\n\", nrow(X_catboost)))\n",
    "cat(sprintf(\"  Features: %d (categorical factors with item names as levels)\\n\", ncol(X_catboost)))\n",
    "cat(sprintf(\"  Target distribution: %d (%.1f%%) positive, %d (%.1f%%) negative\\n\",\n",
    "            sum(y_catboost == 1), 100 * mean(y_catboost == 1), \n",
    "            sum(y_catboost == 0), 100 * mean(y_catboost == 0)))\n",
    "\n",
    "# FOR RANDOM FOREST: Create binary feature matrix (0/1)\n",
    "cat(\"\\nCreating Random Forest format (numeric binary 0/1)...\\n\")\n",
    "feature_matrix_rf <- patient_items %>%\n",
    "  mutate(value = 1) %>%\n",
    "  pivot_wider(\n",
    "    id_cols = mi_person_key,\n",
    "    names_from = item,\n",
    "    values_from = value,\n",
    "    values_fill = 0,\n",
    "    names_prefix = \"item_\"\n",
    "  ) %>%\n",
    "  left_join(patient_targets, by = \"mi_person_key\")\n",
    "\n",
    "data_rf <- feature_matrix_rf %>%\n",
    "  select(-mi_person_key)\n",
    "# Keep as numeric (0/1) for Random Forest\n",
    "\n",
    "y_rf <- data_rf$target\n",
    "X_rf <- data_rf %>% select(-target)\n",
    "\n",
    "cat(sprintf(\"Random Forest format:\\n\"))\n",
    "cat(sprintf(\"  Patients: %d\\n\", nrow(X_rf)))\n",
    "cat(sprintf(\"  Features: %d (numeric binary)\\n\", ncol(X_rf)))\n",
    "\n",
    "# Use CatBoost format by default (categorical factors)\n",
    "data <- data_catboost\n",
    "y <- y_catboost\n",
    "X <- X_catboost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33981d5",
   "metadata": {},
   "source": [
    "## 4. Helper Functions\n",
    "\n",
    "Define functions for training models and calculating feature importance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15567823",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Train CatBoost model (R) - uses categorical factor features\n",
    "train_catboost_r <- function(X_train, y_train, params) {\n",
    "  # X_train should have ALL columns as factors (categorical features)\n",
    "  # R's CatBoost automatically detects factor columns as categorical - no need to specify\n",
    "  # Verify all columns are factors\n",
    "  factor_cols <- names(X_train)[sapply(X_train, is.factor)]\n",
    "  if (length(factor_cols) != ncol(X_train)) {\n",
    "    warning(sprintf(\"Not all columns are factors! Factors: %d, Total: %d\", \n",
    "                    length(factor_cols), ncol(X_train)))\n",
    "  }\n",
    "  \n",
    "  # Create pool - R CatBoost automatically handles factor columns as categorical\n",
    "  train_pool <- catboost.load_pool(\n",
    "    data = X_train, \n",
    "    label = y_train\n",
    "  )\n",
    "  \n",
    "  catboost_params <- list(\n",
    "    iterations = params$iterations,\n",
    "    learning_rate = params$learning_rate,\n",
    "    depth = params$depth,\n",
    "    loss_function = 'Logloss',\n",
    "    eval_metric = 'Recall',\n",
    "    verbose = params$verbose,\n",
    "    logging_level = 'Silent',  # Suppress CatBoost logging to avoid thread safety warnings\n",
    "    random_seed = params$random_seed\n",
    "  )\n",
    "  \n",
    "  model <- catboost.train(train_pool, NULL, catboost_params)\n",
    "  return(model)\n",
    "}\n",
    "\n",
    "# Train Random Forest model (R)\n",
    "train_random_forest_r <- function(X_train, y_train, params) {\n",
    "  if (is.null(params$mtry)) {\n",
    "    params$mtry <- floor(sqrt(ncol(X_train)))\n",
    "  }\n",
    "  \n",
    "  y_train_factor <- as.factor(y_train)\n",
    "  \n",
    "  model <- randomForest(\n",
    "    x = X_train,\n",
    "    y = y_train_factor,\n",
    "    ntree = params$ntree,\n",
    "    mtry = params$mtry,\n",
    "    nodesize = params$nodesize,\n",
    "    maxnodes = params$maxnodes,\n",
    "    importance = TRUE\n",
    "  )\n",
    "  \n",
    "  return(model)\n",
    "}\n",
    "\n",
    "# Get feature importance from CatBoost (R)\n",
    "get_importance_catboost_r <- function(model, X_test) {\n",
    "  # R's CatBoost automatically detects factor columns as categorical - no need to specify\n",
    "  # Verify all columns are factors (should match training)\n",
    "  factor_cols <- names(X_test)[sapply(X_test, is.factor)]\n",
    "  if (length(factor_cols) != ncol(X_test)) {\n",
    "    warning(sprintf(\"Test data: Not all columns are factors! Factors: %d, Total: %d\", \n",
    "                    length(factor_cols), ncol(X_test)))\n",
    "  }\n",
    "  \n",
    "  # Create test pool - R CatBoost automatically handles factor columns as categorical\n",
    "  test_pool <- catboost.load_pool(data = X_test)\n",
    "  \n",
    "  # Get feature importance - ensure it returns a vector\n",
    "  importance <- catboost.get_feature_importance(model, pool = test_pool, type = 'PredictionValuesChange')\n",
    "  \n",
    "  # Ensure importance is a named vector with correct length\n",
    "  if (length(importance) == 1 && ncol(X_test) > 1) {\n",
    "    warning(sprintf(\"Feature importance returned single value instead of vector (expected %d features)\", ncol(X_test)))\n",
    "    # Fallback: return zeros with feature names\n",
    "    importance <- setNames(rep(0, ncol(X_test)), names(X_test))\n",
    "  } else if (length(importance) != ncol(X_test)) {\n",
    "    warning(sprintf(\"Feature importance length mismatch: got %d, expected %d\", length(importance), ncol(X_test)))\n",
    "    # Try to pad or truncate to match\n",
    "    if (length(importance) < ncol(X_test)) {\n",
    "      importance <- c(importance, rep(0, ncol(X_test) - length(importance)))\n",
    "    } else {\n",
    "      importance <- importance[1:ncol(X_test)]\n",
    "    }\n",
    "    names(importance) <- names(X_test)\n",
    "  } else if (is.null(names(importance))) {\n",
    "    # Ensure names are set\n",
    "    names(importance) <- names(X_test)\n",
    "  }\n",
    "  \n",
    "  return(importance)\n",
    "}\n",
    "\n",
    "# Get feature importance from Random Forest (R)\n",
    "get_importance_random_forest_r <- function(model) {\n",
    "  importance <- importance(model)[, \"MeanDecreaseGini\"]\n",
    "  return(importance)\n",
    "}\n",
    "\n",
    "# Calculate metrics for scaling\n",
    "# Handle NA values: remove them before calculation\n",
    "\n",
    "# Calculate Recall\n",
    "calculate_recall <- function(y_true, y_pred) {\n",
    "  # Check inputs\n",
    "  if (length(y_true) != length(y_pred)) {\n",
    "    warning(sprintf(\"Length mismatch: y_true=%d, y_pred=%d\", length(y_true), length(y_pred)))\n",
    "    return(0)\n",
    "  }\n",
    "  \n",
    "  # Remove NA values from both vectors\n",
    "  valid_idx <- !is.na(y_true) & !is.na(y_pred)\n",
    "  \n",
    "  if (sum(valid_idx) == 0) {\n",
    "    warning(sprintf(\"No valid predictions for recall calculation (y_true: %d NAs/%d, y_pred: %d NAs/%d)\", \n",
    "                    sum(is.na(y_true)), length(y_true), sum(is.na(y_pred)), length(y_pred)))\n",
    "    return(0)\n",
    "  }\n",
    "  \n",
    "  y_true_clean <- y_true[valid_idx]\n",
    "  y_pred_clean <- y_pred[valid_idx]\n",
    "  \n",
    "  # Check if we have any valid data\n",
    "  if (length(y_true_clean) == 0) {\n",
    "    warning(\"No valid data after filtering NAs\")\n",
    "    return(0)\n",
    "  }\n",
    "  \n",
    "  tp <- sum((y_true_clean == 1) & (y_pred_clean == 1))\n",
    "  fn <- sum((y_true_clean == 1) & (y_pred_clean == 0))\n",
    "  \n",
    "  # Handle edge case: no positive cases in true labels\n",
    "  if (tp + fn == 0) {\n",
    "    warning(sprintf(\"No positive cases in y_true for recall calculation (total valid: %d, positives: %d)\", \n",
    "                    length(y_true_clean), sum(y_true_clean == 1)))\n",
    "    return(0)\n",
    "  }\n",
    "  \n",
    "  return(tp / (tp + fn))\n",
    "}\n",
    "\n",
    "# Calculate LogLoss (logarithmic loss)\n",
    "# Lower is better, so we'll invert it for scaling (1/logloss or use negative)\n",
    "calculate_logloss <- function(y_true, y_pred_proba) {\n",
    "  # Remove NA values\n",
    "  valid_idx <- !is.na(y_true) & !is.na(y_pred_proba)\n",
    "  if (sum(valid_idx) == 0) {\n",
    "    warning(\"No valid predictions for logloss calculation\")\n",
    "    return(Inf)  # Return Inf so 1/logloss = 0\n",
    "  }\n",
    "  \n",
    "  y_true_clean <- y_true[valid_idx]\n",
    "  y_pred_proba_clean <- y_pred_proba[valid_idx]\n",
    "  \n",
    "  # Clip probabilities to avoid log(0) or log(1)\n",
    "  y_pred_proba_clean <- pmax(pmin(y_pred_proba_clean, 1 - 1e-15), 1e-15)\n",
    "  \n",
    "  # Calculate logloss\n",
    "  logloss <- -mean(y_true_clean * log(y_pred_proba_clean) + (1 - y_true_clean) * log(1 - y_pred_proba_clean))\n",
    "  \n",
    "  return(logloss)\n",
    "}\n",
    "\n",
    "# Predict with CatBoost (R) - returns binary predictions\n",
    "predict_catboost_r <- function(model, X_test) {\n",
    "  # R's CatBoost automatically detects factor columns as categorical - no need to specify\n",
    "  # Create test pool - R CatBoost automatically handles factor columns as categorical\n",
    "  test_pool <- catboost.load_pool(data = X_test)\n",
    "  pred_proba <- catboost.predict(model, test_pool, prediction_type = 'Probability')\n",
    "  \n",
    "  # Handle NA values: if pred_proba is NA, default to 0 (negative class)\n",
    "  pred <- ifelse(is.na(pred_proba), 0, ifelse(pred_proba > 0.5, 1, 0))\n",
    "  \n",
    "  # Ensure no NA values remain\n",
    "  if (any(is.na(pred))) {\n",
    "    warning(\"NA values in CatBoost predictions, replacing with 0\")\n",
    "    pred[is.na(pred)] <- 0\n",
    "  }\n",
    "  \n",
    "  return(pred)\n",
    "}\n",
    "\n",
    "# Predict probabilities with CatBoost (R) - returns probability values\n",
    "predict_proba_catboost_r <- function(model, X_test) {\n",
    "  test_pool <- catboost.load_pool(data = X_test)\n",
    "  pred_proba <- catboost.predict(model, test_pool, prediction_type = 'Probability')\n",
    "  \n",
    "  # Handle NA values\n",
    "  if (any(is.na(pred_proba))) {\n",
    "    warning(\"NA values in CatBoost probability predictions, replacing with 0.5\")\n",
    "    pred_proba[is.na(pred_proba)] <- 0.5\n",
    "  }\n",
    "  \n",
    "  return(pred_proba)\n",
    "}\n",
    "\n",
    "# Predict with Random Forest (R) - returns binary predictions\n",
    "predict_random_forest_r <- function(model, X_test) {\n",
    "  pred <- predict(model, X_test, type = 'response')\n",
    "  pred <- as.integer(pred) - 1  # Convert factor to 0/1\n",
    "  \n",
    "  # Handle NA values: if prediction is NA, default to 0 (negative class)\n",
    "  if (any(is.na(pred))) {\n",
    "    warning(\"NA values in Random Forest predictions, replacing with 0\")\n",
    "    pred[is.na(pred)] <- 0\n",
    "  }\n",
    "  \n",
    "  return(pred)\n",
    "}\n",
    "\n",
    "# Predict probabilities with Random Forest (R) - returns probability values\n",
    "predict_proba_random_forest_r <- function(model, X_test) {\n",
    "  pred_proba <- predict(model, X_test, type = 'prob')[, 2]  # Get probability of class 1\n",
    "  \n",
    "  # Handle NA values\n",
    "  if (any(is.na(pred_proba))) {\n",
    "    warning(\"NA values in Random Forest probability predictions, replacing with 0.5\")\n",
    "    pred_proba[is.na(pred_proba)] <- 0.5\n",
    "  }\n",
    "  \n",
    "  return(pred_proba)\n",
    "}\n",
    "\n",
    "cat(\"‚úì Helper functions defined\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2de9768",
   "metadata": {},
   "source": [
    "## 5. Monte Carlo Cross-Validation\n",
    "\n",
    "Run MC-CV for each model type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c739951",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create MC-CV splits (stratified by target)\n",
    "# Note: We use the CatBoost format (categorical) for splits, but Random Forest will use its own format\n",
    "cat(\"\\n========================================\\n\")\n",
    "cat(\"Creating MC-CV Splits\\n\")\n",
    "cat(\"========================================\\n\")\n",
    "\n",
    "# Validate data before creating splits\n",
    "if (!\"target\" %in% names(data)) {\n",
    "  stop(\"Target column not found in data. Cannot create MC-CV splits.\")\n",
    "}\n",
    "if (all(is.na(data$target))) {\n",
    "  stop(\"Target column is all NA. Cannot create MC-CV splits. Check data loading.\")\n",
    "}\n",
    "cat(sprintf(\"Data for splits (before cleaning): nrow=%d, target NAs=%d, target positives=%d\\n\",\n",
    "            nrow(data), sum(is.na(data$target)), sum(data$target == 1, na.rm = TRUE)))\n",
    "\n",
    "# CRITICAL FIX: Remove any rows with NA target BEFORE creating splits\n",
    "# mc_cv() with strata cannot handle NA values in the strata variable\n",
    "data_clean <- data %>% filter(!is.na(target))\n",
    "if (nrow(data_clean) < nrow(data)) {\n",
    "  warning(sprintf(\"Removed %d rows with NA target values before MC-CV\", nrow(data) - nrow(data_clean)))\n",
    "}\n",
    "data <- data_clean\n",
    "\n",
    "# Also update data_rf to match (remove same rows if they exist)\n",
    "if (exists(\"data_rf\")) {\n",
    "  data_rf_clean <- data_rf %>% filter(!is.na(target))\n",
    "  if (nrow(data_rf_clean) < nrow(data_rf)) {\n",
    "    warning(sprintf(\"Removed %d rows from data_rf with NA target values\", nrow(data_rf) - nrow(data_rf_clean)))\n",
    "  }\n",
    "  data_rf <- data_rf_clean\n",
    "}\n",
    "\n",
    "# Validate minimum sample sizes for stratification\n",
    "target_counts <- table(data$target)\n",
    "min_samples_needed <- ceiling(N_SPLITS * TEST_SIZE * 2)  # Need at least 2 samples per class per split\n",
    "cat(sprintf(\"\\nAfter cleaning:\\n\"))\n",
    "cat(sprintf(\"  Total samples: %d\\n\", nrow(data)))\n",
    "cat(sprintf(\"  Target distribution: 0=%d (%.1f%%), 1=%d (%.1f%%)\\n\", \n",
    "            target_counts[1], 100*target_counts[1]/sum(target_counts),\n",
    "            target_counts[2], 100*target_counts[2]/sum(target_counts)))\n",
    "cat(sprintf(\"  Min samples needed per class: %d (for %d splits with %.0f%% test)\\n\",\n",
    "            min_samples_needed, N_SPLITS, TEST_SIZE*100))\n",
    "\n",
    "if (any(target_counts < min_samples_needed)) {\n",
    "  warning(sprintf(\"‚ö†Ô∏è  Small sample size detected for stratification!\\n\"))\n",
    "  warning(sprintf(\"   Consider: reducing N_SPLITS, increasing TEST_SIZE, or using more data.\\n\"))\n",
    "}\n",
    "\n",
    "mc_splits <- mc_cv(\n",
    "  data = data,\n",
    "  prop = TRAIN_PROP,\n",
    "  times = N_SPLITS,\n",
    "  strata = target  # Stratified by target (bare name - rsample uses non-standard evaluation)\n",
    ")\n",
    "\n",
    "cat(sprintf(\"\\n‚úì Created %d MC-CV splits (stratified)\\n\", N_SPLITS))\n",
    "cat(\"Note: CatBoost uses categorical features, Random Forest uses one-hot encoded features\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f8004a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Run MC-CV for a single model type\n",
    "run_mc_cv_method <- function(data, method, mc_splits, data_rf = NULL) {\n",
    "  cat(sprintf(\"\\n--- Running MC-CV for %s ---\\n\", method))\n",
    "  \n",
    "  # Use appropriate data format for each model\n",
    "  if (method == \"catboost\") {\n",
    "    # CatBoost: use categorical format\n",
    "    # Check if target column exists\n",
    "    if (!\"target\" %in% names(data)) {\n",
    "      stop(\"Target column not found in data. Check that data includes target column.\")\n",
    "    }\n",
    "    X <- data %>% select(-target)\n",
    "    y <- data$target\n",
    "    \n",
    "    # Validate y\n",
    "    if (all(is.na(y))) {\n",
    "      stop(\"Target column (y) is all NA. Check data loading and target extraction.\")\n",
    "    }\n",
    "    if (DEBUG_MODE) {\n",
    "      cat(sprintf(\"  Data check: nrow=%d, ncol=%d, target NAs=%d, target positives=%d\\n\",\n",
    "                  nrow(data), ncol(data), sum(is.na(y)), sum(y == 1, na.rm = TRUE)))\n",
    "    }\n",
    "  } else if (method == \"random_forest\") {\n",
    "    # Random Forest: use one-hot encoded format\n",
    "    if (is.null(data_rf)) {\n",
    "      stop(\"Random Forest requires data_rf (one-hot encoded format)\")\n",
    "    }\n",
    "    if (!\"target\" %in% names(data_rf)) {\n",
    "      stop(\"Target column not found in data_rf. Check that data_rf includes target column.\")\n",
    "    }\n",
    "    X <- data_rf %>% select(-target)\n",
    "    y <- data_rf$target\n",
    "    \n",
    "    # Validate y\n",
    "    if (all(is.na(y))) {\n",
    "      stop(\"Target column (y) in data_rf is all NA. Check data loading and target extraction.\")\n",
    "    }\n",
    "  } else {\n",
    "    stop(sprintf(\"Unknown method: %s\", method))\n",
    "  }\n",
    "  \n",
    "  feature_names <- colnames(X)\n",
    "  \n",
    "  # Create progress bar\n",
    "  p <- progressor(steps = N_SPLITS)\n",
    "  \n",
    "  # Run MC-CV in parallel\n",
    "  results <- future_map(1:N_SPLITS, function(i) {\n",
    "    p()\n",
    "    \n",
    "    # Get train/test split\n",
    "    split <- mc_splits$splits[[i]]\n",
    "    train_idx <- split$in_id\n",
    "    test_idx <- split$out_id\n",
    "    \n",
    "    # Validate indices (handle empty vectors and NA values)\n",
    "    if (length(train_idx) == 0) {\n",
    "      stop(sprintf(\"[Split %d] Empty train_idx\", i))\n",
    "    }\n",
    "    if (length(test_idx) == 0) {\n",
    "      stop(sprintf(\"[Split %d] Empty test_idx\", i))\n",
    "    }\n",
    "    \n",
    "    # Check for NA values in indices and remove them\n",
    "    if (any(is.na(train_idx))) {\n",
    "      warning(sprintf(\"[Split %d] train_idx contains %d NA values, removing them\", \n",
    "                      i, sum(is.na(train_idx))))\n",
    "      train_idx <- train_idx[!is.na(train_idx)]\n",
    "    }\n",
    "    if (any(is.na(test_idx))) {\n",
    "      warning(sprintf(\"[Split %d] test_idx contains %d NA values, removing them\", \n",
    "                      i, sum(is.na(test_idx))))\n",
    "      test_idx <- test_idx[!is.na(test_idx)]\n",
    "    }\n",
    "    \n",
    "    # Re-check after removing NAs\n",
    "    if (length(train_idx) == 0) {\n",
    "      stop(sprintf(\"[Split %d] train_idx is empty after removing NAs\", i))\n",
    "    }\n",
    "    if (length(test_idx) == 0) {\n",
    "      stop(sprintf(\"[Split %d] test_idx is empty after removing NAs\", i))\n",
    "    }\n",
    "    \n",
    "    max_train <- max(train_idx, na.rm = TRUE)\n",
    "    max_test <- max(test_idx, na.rm = TRUE)\n",
    "    \n",
    "    if (is.infinite(max_train) || is.infinite(max_test)) {\n",
    "      stop(sprintf(\"[Split %d] Invalid max indices: max(train_idx)=%s, max(test_idx)=%s\",\n",
    "                   i, ifelse(is.infinite(max_train), \"Inf\", as.character(max_train)),\n",
    "                   ifelse(is.infinite(max_test), \"Inf\", as.character(max_test))))\n",
    "    }\n",
    "    \n",
    "    if (max_train > length(y) || max_test > length(y)) {\n",
    "      stop(sprintf(\"[Split %d] Index out of bounds: max(train_idx)=%d, max(test_idx)=%d, length(y)=%d\",\n",
    "                   i, max_train, max_test, length(y)))\n",
    "    }\n",
    "    \n",
    "    X_train <- X[train_idx, , drop = FALSE]\n",
    "    X_test <- X[test_idx, , drop = FALSE]\n",
    "    y_train <- y[train_idx]\n",
    "    y_test <- y[test_idx]\n",
    "    \n",
    "    # Validate extracted y_test\n",
    "    if (all(is.na(y_test))) {\n",
    "      warning(sprintf(\"[Split %d] y_test is all NA. y length=%d, test_idx length=%d, y NAs=%d\",\n",
    "                      i, length(y), length(test_idx), sum(is.na(y))))\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    model <- NULL\n",
    "    if (method == \"catboost\") {\n",
    "      model <- train_catboost_r(X_train, y_train, MODEL_PARAMS$catboost)\n",
    "    } else if (method == \"random_forest\") {\n",
    "      model <- train_random_forest_r(X_train, y_train, MODEL_PARAMS$random_forest)\n",
    "    } else {\n",
    "      stop(sprintf(\"Unknown method: %s\", method))\n",
    "    }\n",
    "    \n",
    "    # Get predictions (binary and probabilities)\n",
    "    if (method == \"catboost\") {\n",
    "      y_pred <- predict_catboost_r(model, X_test)\n",
    "      y_pred_proba <- predict_proba_catboost_r(model, X_test)\n",
    "    } else if (method == \"random_forest\") {\n",
    "      y_pred <- predict_random_forest_r(model, X_test)\n",
    "      y_pred_proba <- predict_proba_random_forest_r(model, X_test)\n",
    "    }\n",
    "    \n",
    "    # Calculate metrics based on SCALING_METRIC setting\n",
    "    if (SCALING_METRIC == \"recall\") {\n",
    "      # Calculate Recall\n",
    "      if (DEBUG_MODE && i <= 2) {\n",
    "        cat(sprintf(\"  [Split %d] y_test: length=%d, NAs=%d, positives=%d\\n\", \n",
    "                    i, length(y_test), sum(is.na(y_test)), sum(y_test == 1, na.rm = TRUE)))\n",
    "        cat(sprintf(\"  [Split %d] y_pred: length=%d, NAs=%d, positives=%d\\n\", \n",
    "                    i, length(y_pred), sum(is.na(y_pred)), sum(y_pred == 1, na.rm = TRUE)))\n",
    "      }\n",
    "      metric_value <- calculate_recall(y_test, y_pred)\n",
    "    } else if (SCALING_METRIC == \"logloss\") {\n",
    "      # Calculate LogLoss (inverted for scaling: 1/logloss so higher = better)\n",
    "      logloss <- calculate_logloss(y_test, y_pred_proba)\n",
    "      metric_value <- if (is.infinite(logloss) || logloss == 0) 0 else (1 / logloss)\n",
    "      if (DEBUG_MODE && i <= 2) {\n",
    "        cat(sprintf(\"  [Split %d] LogLoss: %.4f, Inverted: %.4f\\n\", i, logloss, metric_value))\n",
    "      }\n",
    "    } else {\n",
    "      stop(sprintf(\"Unknown SCALING_METRIC: %s. Use 'recall' or 'logloss'\", SCALING_METRIC))\n",
    "    }\n",
    "    \n",
    "    # Get feature importance\n",
    "    if (method == \"catboost\") {\n",
    "      # CatBoost handles character columns directly - no conversion needed\n",
    "      importance <- get_importance_catboost_r(model, X_test)\n",
    "    } else if (method == \"random_forest\") {\n",
    "      importance <- get_importance_random_forest_r(model)\n",
    "    }\n",
    "    \n",
    "    # Validate importance vector\n",
    "    expected_length <- if (method == \"catboost\") ncol(X) else ncol(X_rf)\n",
    "    if (length(importance) != expected_length) {\n",
    "      warning(sprintf(\"[Split %d] Importance length mismatch: got %d, expected %d. Using zeros.\", \n",
    "                      i, length(importance), expected_length))\n",
    "      importance <- setNames(rep(0, expected_length), \n",
    "                            if (method == \"catboost\") names(X) else names(X_rf))\n",
    "    }\n",
    "    \n",
    "    # Return results\n",
    "    list(\n",
    "      model = model,\n",
    "      metric_value = metric_value,\n",
    "      importance = importance\n",
    "    )\n",
    "  }, .options = furrr_options(seed = 42))\n",
    "  \n",
    "  # Extract results\n",
    "  metric_values <- map_dbl(results, ~ .x$metric_value)\n",
    "  importance_list <- map(results, ~ .x$importance)\n",
    "  \n",
    "  # Validate importance vectors before creating matrix\n",
    "  importance_lengths <- map_int(importance_list, length)\n",
    "  expected_length <- length(feature_names)\n",
    "  \n",
    "  if (any(importance_lengths != expected_length)) {\n",
    "    warning(sprintf(\"Importance length mismatch detected. Expected %d, got: %s\", \n",
    "                    expected_length, paste(unique(importance_lengths), collapse = \", \")))\n",
    "    # Fix any mismatched importance vectors\n",
    "    importance_list <- map(importance_list, function(imp) {\n",
    "      if (length(imp) != expected_length) {\n",
    "        if (length(imp) == 1) {\n",
    "          # Single value - create zero vector\n",
    "          setNames(rep(0, expected_length), feature_names)\n",
    "        } else {\n",
    "          # Wrong length - pad or truncate\n",
    "          if (length(imp) < expected_length) {\n",
    "            imp <- c(imp, rep(0, expected_length - length(imp)))\n",
    "          } else {\n",
    "            imp <- imp[1:expected_length]\n",
    "          }\n",
    "          setNames(imp, feature_names)\n",
    "        }\n",
    "      } else {\n",
    "        imp\n",
    "      }\n",
    "    })\n",
    "  }\n",
    "  \n",
    "  # Create matrix from validated importance vectors\n",
    "  importance_matrix <- do.call(rbind, importance_list)\n",
    "  \n",
    "  # Validate matrix dimensions\n",
    "  if (ncol(importance_matrix) != expected_length) {\n",
    "    stop(sprintf(\"Importance matrix has wrong number of columns: got %d, expected %d\", \n",
    "                 ncol(importance_matrix), expected_length))\n",
    "  }\n",
    "  \n",
    "  # Average importance across splits\n",
    "  avg_importance <- colMeans(importance_matrix)\n",
    "  names(avg_importance) <- feature_names\n",
    "  \n",
    "  # Normalize importance (0-1 scale)\n",
    "  min_imp <- min(avg_importance)\n",
    "  max_imp <- max(avg_importance)\n",
    "  if (max_imp > min_imp) {\n",
    "    normalized_importance <- (avg_importance - min_imp) / (max_imp - min_imp)\n",
    "  } else {\n",
    "    normalized_importance <- rep(1 / length(avg_importance), length(avg_importance))\n",
    "  }\n",
    "  \n",
    "  # Scale by mean MC-CV metric value\n",
    "  mean_metric <- mean(metric_values)\n",
    "  scaled_importance <- normalized_importance * mean_metric\n",
    "  \n",
    "  # Create results DataFrame\n",
    "  metric_name <- if (SCALING_METRIC == \"recall\") \"recall\" else \"logloss_inverted\"\n",
    "  results_df <- tibble(\n",
    "    feature = feature_names,\n",
    "    importance_raw = avg_importance,\n",
    "    importance_normalized = normalized_importance,\n",
    "    importance_scaled = scaled_importance,\n",
    "    model_type = method,\n",
    "    mc_cv_metric_mean = mean_metric,\n",
    "    mc_cv_metric_std = sd(metric_values)\n",
    "  ) %>%\n",
    "    arrange(desc(importance_scaled)) %>%\n",
    "    mutate(rank = row_number())\n",
    "  \n",
    "  # Rename metric column for clarity\n",
    "  names(results_df)[names(results_df) == \"mc_cv_metric_mean\"] <- sprintf(\"mc_cv_%s_mean\", metric_name)\n",
    "  names(results_df)[names(results_df) == \"mc_cv_metric_std\"] <- sprintf(\"mc_cv_%s_std\", metric_name)\n",
    "  \n",
    "  cat(sprintf(\"  Mean %s: %.4f ¬± %.4f\\n\", \n",
    "              if (SCALING_METRIC == \"recall\") \"Recall\" else \"LogLoss (inverted)\", \n",
    "              mean_metric, sd(metric_values)))\n",
    "  cat(sprintf(\"  Top 50 features:\\n\"))\n",
    "  top50 <- head(results_df, 50)\n",
    "  for (i in 1:nrow(top50)) {\n",
    "    cat(sprintf(\"    %d. %s (scaled=%.6f)\\n\", \n",
    "                top50$rank[i], top50$feature[i], top50$importance_scaled[i]))\n",
    "  }\n",
    "  \n",
    "  return(results_df)\n",
    "}\n",
    "\n",
    "cat(\"‚úì MC-CV function defined\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3b2699",
   "metadata": {},
   "source": [
    "## 6. Run Analysis\n",
    "\n",
    "Run MC-CV for each model type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d67d8d5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Run each method\n",
    "methods <- c(\"catboost\", \"random_forest\")\n",
    "all_results <- list()\n",
    "\n",
    "# Note: data_rf was created in the feature engineering step above\n",
    "# Both data and data_rf should have the same number of rows and same patient order\n",
    "\n",
    "for (method in methods) {\n",
    "  if (method == \"random_forest\") {\n",
    "    result <- run_mc_cv_method(data, method, mc_splits, data_rf = data_rf)\n",
    "  } else {\n",
    "    result <- run_mc_cv_method(data, method, mc_splits)\n",
    "  }\n",
    "  all_results[[method]] <- result\n",
    "  \n",
    "  # Save individual results\n",
    "  output_file <- file.path(output_dir, sprintf(\"%s_%s_%s_%d_%s_feature_importance.csv\",\n",
    "                                                COHORT_NAME, AGE_BAND, EVENT_YEAR, method))\n",
    "  write_csv(result, output_file)\n",
    "  cat(sprintf(\"Saved: %s\\n\", output_file))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bb106e",
   "metadata": {},
   "source": [
    "## 7. Aggregate Results\n",
    "\n",
    "Combine results across models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df12cf6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate across models\n",
    "cat(\"\\n========================================\\n\")\n",
    "cat(\"Aggregating Results Across Models\\n\")\n",
    "cat(\"========================================\\n\")\n",
    "\n",
    "combined_df <- bind_rows(all_results)\n",
    "\n",
    "# Aggregate by feature (average scaled importance)\n",
    "# Get metric column names dynamically\n",
    "metric_mean_col <- sprintf(\"mc_cv_%s_mean\", if (SCALING_METRIC == \"recall\") \"recall\" else \"logloss_inverted\")\n",
    "metric_std_col <- sprintf(\"mc_cv_%s_std\", if (SCALING_METRIC == \"recall\") \"recall\" else \"logloss_inverted\")\n",
    "\n",
    "aggregated <- combined_df %>%\n",
    "  group_by(feature) %>%\n",
    "  summarise(\n",
    "    importance_raw = mean(importance_raw),\n",
    "    importance_normalized = mean(importance_normalized),\n",
    "    importance_scaled = mean(importance_scaled),\n",
    "    metric_mean = mean(.data[[metric_mean_col]]),\n",
    "    metric_std = mean(.data[[metric_std_col]]),\n",
    "    .groups = 'drop'\n",
    "  ) %>%\n",
    "  arrange(desc(importance_scaled)) %>%\n",
    "  mutate(rank = row_number())\n",
    "\n",
    "# Rename metric columns for clarity\n",
    "names(aggregated)[names(aggregated) == \"metric_mean\"] <- metric_mean_col\n",
    "names(aggregated)[names(aggregated) == \"metric_std\"] <- metric_std_col\n",
    "\n",
    "# Save aggregated results\n",
    "output_file <- file.path(output_dir, sprintf(\"%s_%s_%d_feature_importance_aggregated.csv\",\n",
    "                                              COHORT_NAME, AGE_BAND, EVENT_YEAR))\n",
    "write_csv(aggregated, output_file)\n",
    "cat(sprintf(\"Saved: %s\\n\", output_file))\n",
    "\n",
    "# Print summary\n",
    "cat(\"\\n========================================\\n\")\n",
    "cat(\"Summary\\n\")\n",
    "cat(\"========================================\\n\")\n",
    "cat(sprintf(\"Total features: %d\\n\", nrow(aggregated)))\n",
    "cat(sprintf(\"Models used: %s\\n\", paste(methods, collapse = \", \")))\n",
    "cat(sprintf(\"Mean MC-CV %s: %.4f\\n\", \n",
    "            if (SCALING_METRIC == \"recall\") \"Recall\" else \"LogLoss (inverted)\",\n",
    "            mean(aggregated[[metric_mean_col]])))\n",
    "cat(\"\\nTop 50 features:\\n\")\n",
    "top50 <- head(aggregated, 50)\n",
    "for (i in 1:nrow(top50)) {\n",
    "  cat(sprintf(\"  %2d. %-40s | scaled=%.6f | %s=%.4f\\n\",\n",
    "              top50$rank[i], top50$feature[i], top50$importance_scaled[i], \n",
    "              if (SCALING_METRIC == \"recall\") \"recall\" else \"logloss_inv\",\n",
    "              top50[[metric_mean_col]][i]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea613ec0",
   "metadata": {},
   "source": [
    "# Cleanup\n",
    "\n",
    "Close parallel processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425a78ce",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Close parallel processing\n",
    "plan(sequential)\n",
    "\n",
    "cat(\"\\n========================================\\n\")\n",
    "cat(\"Analysis Complete!\\n\")\n",
    "cat(\"========================================\\n\")\n",
    "cat(sprintf(\"Output directory: %s\\n\", output_dir))\n",
    "cat(sprintf(\"MC-CV splits: %d\\n\", N_SPLITS))\n",
    "cat(sprintf(\"Train/Test ratio: %.0f/%.0f\\n\", TRAIN_PROP * 100, TEST_SIZE * 100))\n",
    "cat(\"\\nResults show scaled feature importance with MC-CV Recall scores\\n\")\n",
    "cat(\"based on\", N_SPLITS, \"independent train/test splits.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065a50ea-25c9-4119-8ede-abc6a754e136",
   "metadata": {},
   "source": [
    "# Sync Results and Code to S3\n",
    "\n",
    "Sync output files and code (notebook + R script) to S3 bucket. \n",
    "- Outputs: CSV results files\n",
    "- Code: Notebook and R script for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861a2d43-3d45-4f58-9489-4380acfccd6f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Sync outputs and code to S3\n",
    "# On EC2, we're in the feature_importance directory\n",
    "s3_bucket <- \"s3://pgx-repository/pgx-analysis/3_feature_importance/\"\n",
    "\n",
    "# Find AWS CLI (check common locations - EC2 typically has it in /usr/local/bin or /usr/bin)\n",
    "aws_cmd <- Sys.which(\"aws\")\n",
    "if (aws_cmd == \"\") {\n",
    "  # Try common EC2 installation paths\n",
    "  aws_paths <- c(\n",
    "    \"/usr/local/bin/aws\",\n",
    "    \"/usr/bin/aws\",\n",
    "    \"/home/ec2-user/.local/bin/aws\"\n",
    "  )\n",
    "  aws_cmd <- NULL\n",
    "  for (path in aws_paths) {\n",
    "    if (file.exists(path)) {\n",
    "      aws_cmd <- path\n",
    "      break\n",
    "    }\n",
    "  }\n",
    "  if (is.null(aws_cmd)) {\n",
    "    stop(\"AWS CLI not found. Please install AWS CLI or ensure it's in your PATH.\")\n",
    "  }\n",
    "}\n",
    "\n",
    "cat(\"Syncing outputs and code to S3...\\n\")\n",
    "cat(\"Source: feature_importance/ directory\\n\")\n",
    "cat(\"Destination:\", s3_bucket, \"\\n\")\n",
    "cat(\"AWS CLI:\", aws_cmd, \"\\n\\n\")\n",
    "\n",
    "# Get current directory (should be feature_importance)\n",
    "current_dir <- getwd()\n",
    "if (!grepl(\"feature_importance\", current_dir)) {\n",
    "  warning(\"Current directory doesn't appear to be feature_importance. Double-check sync destination.\")\n",
    "}\n",
    "\n",
    "# Sync feature_importance directory (includes outputs/ and code files)\n",
    "# Explicitly include notebook, R scripts, README files, and outputs directory\n",
    "# Exclude temporary files, checkpoints, and unnecessary directories\n",
    "# Note: --delete flag removed for safety (won't delete files in S3 that don't exist locally)\n",
    "# Include patterns are processed before exclude patterns, then exclude everything else\n",
    "sync_cmd <- sprintf(\n",
    "  '\"%s\" s3 sync \"%s\" %s --include \"*.ipynb\" --include \"*.R\" --include \"README*.md\" --include \"outputs/**\" --exclude \"*checkpoint*\" --exclude \"*.tmp\" --exclude \"*.ipynb_checkpoints/*\" --exclude \"*.RData\" --exclude \"*.Rhistory\" --exclude \".Rproj.user/*\" --exclude \"catboost_info/*\" --exclude \"*.log\" --exclude \"*\"',\n",
    "  aws_cmd,\n",
    "  current_dir,\n",
    "  s3_bucket\n",
    ")\n",
    "\n",
    "cat(\"Running:\", sync_cmd, \"\\n\\n\")\n",
    "result <- system(sync_cmd)\n",
    "\n",
    "if (result == 0) {\n",
    "  cat(\"‚úì Successfully synced outputs and code to S3\\n\")\n",
    "  cat(\"  - Outputs:\", file.path(output_dir), \"\\n\")\n",
    "  cat(\"  - Code: *.ipynb, *.R, README*.md\\n\")\n",
    "} else {\n",
    "  warning(sprintf(\"S3 sync returned exit code %d. Check AWS credentials and permissions.\", result))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770b6d05-c977-4040-ae45-e6a05ad690d7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "832bf4fd-dc62-4c54-89a2-1b9d2d251a76",
   "metadata": {},
   "source": [
    "# Shutdown EC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6315b0bf-daaa-4543-a9f0-a0a663f3daf5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Shutdown EC2 instance after analysis completes\n",
    "# Set SHUTDOWN_EC2 = TRUE to enable, FALSE to disable\n",
    "SHUTDOWN_EC2 <- TRUE  # Change to TRUE to enable auto-shutdown\n",
    "\n",
    "if (SHUTDOWN_EC2) {\n",
    "  cat(\"\\n========================================\\n\")\n",
    "  cat(\"Shutting down EC2 instance...\\n\")\n",
    "  cat(\"========================================\\n\")\n",
    "  \n",
    "  # Get instance ID from EC2 metadata service\n",
    "  instance_id <- tryCatch({\n",
    "    system(\"curl -s http://169.254.169.254/latest/meta-data/instance-id\", intern = TRUE)\n",
    "  }, error = function(e) {\n",
    "    cat(\"Warning: Could not retrieve instance ID from metadata service.\\n\")\n",
    "    cat(\"If running on EC2, check that metadata service is accessible.\\n\")\n",
    "    return(NULL)\n",
    "  })\n",
    "  \n",
    "  if (!is.null(instance_id) && length(instance_id) > 0 && nchar(instance_id[1]) > 0) {\n",
    "    instance_id <- instance_id[1]\n",
    "    cat(sprintf(\"Instance ID: %s\\n\", instance_id))\n",
    "    \n",
    "    # Find AWS CLI\n",
    "    aws_cmd <- Sys.which(\"aws\")\n",
    "    if (aws_cmd == \"\") {\n",
    "      aws_paths <- c(\n",
    "        \"/usr/local/bin/aws\",\n",
    "        \"/usr/bin/aws\",\n",
    "        \"/home/ec2-user/.local/bin/aws\"\n",
    "      )\n",
    "      aws_cmd <- NULL\n",
    "      for (path in aws_paths) {\n",
    "        if (file.exists(path)) {\n",
    "          aws_cmd <- path\n",
    "          break\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    if (!is.null(aws_cmd) && aws_cmd != \"\") {\n",
    "      # Stop the instance (use terminate-instances for permanent deletion)\n",
    "      shutdown_cmd <- sprintf(\n",
    "        '\"%s\" ec2 stop-instances --instance-ids %s',\n",
    "        aws_cmd,\n",
    "        instance_id\n",
    "      )\n",
    "      \n",
    "      cat(\"Running:\", shutdown_cmd, \"\\n\")\n",
    "      result <- system(shutdown_cmd)\n",
    "      \n",
    "      if (result == 0) {\n",
    "        cat(\"‚úì EC2 instance stop command sent successfully\\n\")\n",
    "        cat(\"Instance will stop in a few moments.\\n\")\n",
    "        cat(\"Note: This is a STOP (not terminate), so you can restart it later.\\n\")\n",
    "      } else {\n",
    "        warning(sprintf(\"EC2 stop command returned exit code %d. Check AWS credentials and permissions.\", result))\n",
    "      }\n",
    "    } else {\n",
    "      cat(\"Warning: AWS CLI not found. Cannot shutdown instance.\\n\")\n",
    "      cat(\"Install AWS CLI or ensure it's in your PATH.\\n\")\n",
    "    }\n",
    "  } else {\n",
    "    cat(\"Warning: Could not determine instance ID. Skipping shutdown.\\n\")\n",
    "    cat(\"If you want to shutdown manually, use:\\n\")\n",
    "    cat(\"  aws ec2 stop-instances --instance-ids <your-instance-id>\\n\")\n",
    "  }\n",
    "} else {\n",
    "  cat(\"\\n========================================\\n\")\n",
    "  cat(\"EC2 Auto-Shutdown: DISABLED\\n\")\n",
    "  cat(\"========================================\\n\")\n",
    "  cat(\"To enable auto-shutdown, set SHUTDOWN_EC2 = TRUE in this cell.\\n\")\n",
    "  cat(\"Instance will continue running.\\n\")\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R (PGX-Analysis)",
   "language": "R",
   "name": "pgx-analysis"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
