{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance Cohort Runner (EC2)\n",
    "\n",
    "This notebook is designed to run the **feature importance Monte Carlo CV pipeline** for all configured cohorts on an **EC2 instance**.\n",
    "\n",
    "- **Cohort scripts**: `3_feature_importance/run_cohort_*.py`\n",
    "- **Data location (EC2)**: `/mnt/nvme/cohorts` (synced from `s3://pgxdatalake/gold/cohorts_F1120/`)\n",
    "- **Environment**: Python environment with `xgboost`, `catboost`, `lightgbm`, `scikit-learn`, `pandas`, `numpy`, etc.\n",
    "\n",
    "**Purpose:** Calculate scaled feature importance across various MLalgorithms\n",
    "**Method:** Normalized feature importance scaled by MC-CV Recall scores  \n",
    "**Hardware:** Optimized for EC2 (32 cores, 1TB RAM)  \n",
    "\n",
    "## Key Features\n",
    "\n",
    "✅ **Monte Carlo Cross-Validation** – up to 1000 random train/test splits (100-split runs used for faster iteration)  \n",
    "✅ **Stratified Sampling** - Maintains target distribution  \n",
    "✅ **95% Confidence Intervals** - Narrow, precise estimates (tighter with more splits)  \n",
    "✅ **Multiple Models** - CatBoost (R) and Random Forest (R)  \n",
    "\n",
    "## Methodology\n",
    "\n",
    "This notebook implements the feature selection methodology:\n",
    "\n",
    "1. Load cohort data from parquet files (same as FP-Growth notebook)\n",
    "2. Create patient-level features (one-hot encoding of items)\n",
    "3. For each model type:\n",
    "   - Create 100–1000 stratified train/test splits\n",
    "   - Train model on training set\n",
    "   - Evaluate Recall on unseen test set\n",
    "   - Extract feature importance\n",
    "   - Aggregate results across splits\n",
    "4. Normalize and scale feature importance by MC-CV Recall\n",
    "5. Aggregate across models\n",
    "6. Extract top features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Project root: /home/pgx3874/pgx-analysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Resolve project_root robustly for BOTH notebook + script mode\n",
    "# -------------------------------------------------------------\n",
    "def resolve_project_root():\n",
    "    # Case 1: running as a script → __file__ exists\n",
    "    if '__file__' in globals():\n",
    "        return Path(__file__).resolve().parents[1]\n",
    "\n",
    "    # Case 2: running in Jupyter/Notebook → no __file__\n",
    "    # Fallback = assume notebook is running inside project folder structure\n",
    "    notebook_path = Path(os.getcwd()).resolve()\n",
    "\n",
    "    # If running in .../pgx-analysis/3_feature_importance, go up 1 level\n",
    "    if notebook_path.name == \"3_feature_importance\":\n",
    "        return notebook_path.parent\n",
    "\n",
    "    # If running deeper inside scripts, go up until pgx-analysis appears\n",
    "    for parent in notebook_path.parents:\n",
    "        if parent.name == \"pgx-analysis\":\n",
    "            return parent\n",
    "\n",
    "    # Last fallback: use current working directory\n",
    "    return notebook_path\n",
    "\n",
    "\n",
    "project_root = resolve_project_root()\n",
    "print(f\"[INFO] Project root: {project_root}\")\n",
    "\n",
    "# Add to sys.path if needed\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per-Cohort Runner Cells\n",
    "\n",
    "Each cell below runs a **single cohort script**. This makes it easy to:\n",
    "\n",
    "- Debug failures for a specific cohort/age-band\n",
    "- Modify a cohort script and immediately re-run just that cohort\n",
    "\n",
    "All cells assume this notebook is running from the `3_feature_importance/` directory (the default when opened from Jupyter in the project root).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort 1 – Age 0–12\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running feature importance analysis:\n",
      "  Cohort: opioid_ed\n",
      "  Age Band: 0-12\n",
      "  Train Years: [2016, 2017, 2018]\n",
      "  Test Year: 2019\n",
      "  MC-CV Splits: 200\n",
      "  Workers: 30\n",
      "  Output Directory: 3_feature_importance/outputs\n",
      "\n",
      "Note: This script is idempotent - models with existing results in S3 will be skipped.\n",
      "\n",
      "2025-11-27 07:37:47,363 - INFO - ================================================================================\n",
      "2025-11-27 07:37:47,363 - INFO - FEATURE IMPORTANCE ANALYSIS - MONTE CARLO CROSS-VALIDATION\n",
      "2025-11-27 07:37:47,363 - INFO - ================================================================================\n",
      "2025-11-27 07:37:47,363 - INFO - Cohort: opioid_ed\n",
      "2025-11-27 07:37:47,363 - INFO - Age Band: 0-12\n",
      "2025-11-27 07:37:47,363 - INFO - Train Years: 2016, 2017, 2018\n",
      "2025-11-27 07:37:47,363 - INFO - Test Year: 2019\n",
      "2025-11-27 07:37:47,364 - INFO - MC-CV Splits: 200\n",
      "2025-11-27 07:37:47,364 - INFO - Scaling Metric: recall\n",
      "2025-11-27 07:37:47,364 - INFO - Debug Mode: Disabled\n",
      "2025-11-27 07:37:47,364 - INFO - ================================================================================\n",
      "2025-11-27 07:37:47,364 - INFO - Loading cohort data...\n",
      "2025-11-27 07:37:47,364 - INFO - Memory usage [Before Data Loading]: 340.1 MB\n",
      "2025-11-27 07:37:47,364 - INFO - Loading training data from years: 2016, 2017, 2018\n",
      "2025-11-27 07:37:47,409 - INFO - Loaded 438 records from year 2016\n",
      "2025-11-27 07:37:47,422 - INFO - Loaded 856 records from year 2017\n",
      "2025-11-27 07:37:47,436 - INFO - Loaded 892 records from year 2018\n",
      "2025-11-27 07:37:47,443 - INFO - Combined training data: 2186 event-level records, 78 unique patients\n",
      "2025-11-27 07:37:47,443 - INFO - Loading test data from year: 2019\n",
      "2025-11-27 07:37:47,458 - INFO - Test data: 1936 event-level records, 66 unique patients\n",
      "2025-11-27 07:37:47,458 - INFO - Memory usage [After Data Loading]: 344.7 MB\n",
      "2025-11-27 07:37:47,458 - INFO - Creating patient-level features for training data...\n",
      "2025-11-27 07:37:47,473 - INFO - Creating patient-level features for test data...\n",
      "2025-11-27 07:37:47,479 - INFO - Total unique items across train and test: 768\n",
      "2025-11-27 07:37:47,952 - INFO - Filtering constant features...\n",
      "2025-11-27 07:37:47,952 - INFO - Items in training data: 549\n",
      "2025-11-27 07:37:47,952 - INFO - Items in test data: 421\n",
      "2025-11-27 07:37:47,952 - INFO - Total items (train + test): 768\n",
      "2025-11-27 07:37:47,952 - INFO - Sample training items: ['G0378', '81025', 'H6121', '90472', 'IBUPROFEN']\n",
      "2025-11-27 07:37:47,955 - INFO - Item '81025': nunique=2, sample values: {'': 75, '81025': 3}\n",
      "2025-11-27 07:37:47,958 - INFO - Item '90472': nunique=2, sample values: {'': 76, '90472': 2}\n",
      "2025-11-27 07:37:47,964 - INFO - Item 'G0378': nunique=2, sample values: {'': 77, 'G0378': 1}\n",
      "2025-11-27 07:37:47,965 - INFO - Item 'H6121': nunique=2, sample values: {'': 77, 'H6121': 1}\n",
      "2025-11-27 07:37:47,966 - INFO - Item 'IBUPROFEN': nunique=2, sample values: {'': 75, 'IBUPROFEN': 3}\n",
      "2025-11-27 07:37:47,973 - INFO - Removing 219 constant features (out of 768 total)\n",
      "2025-11-27 07:37:47,975 - INFO - Saved constant features list: 3_feature_importance/outputs/opioid_ed_0_12_constant_features.csv\n",
      "2025-11-27 07:37:48,140 - INFO - Uploaded constant features to S3: s3://pgxdatalake/gold/feature_importance/model_metadata/opioid_ed/0-12_constant_features.csv\n",
      "2025-11-27 07:37:48,142 - INFO - Feature engineering complete:\n",
      "2025-11-27 07:37:48,142 - INFO -   Training: 78 patients, 549 features\n",
      "2025-11-27 07:37:48,142 - INFO -   Test: 66 patients, 549 features\n",
      "2025-11-27 07:37:48,142 - INFO - Memory usage [After Feature Engineering]: 351.7 MB\n",
      "2025-11-27 07:37:48,142 - INFO - Creating MC-CV splits (sampling from train years, testing on 2019)...\n",
      "2025-11-27 07:37:48,142 - INFO - Memory usage [Before MC-CV Split Creation]: 351.7 MB\n",
      "2025-11-27 07:37:48,159 - INFO - Created 200 MC-CV splits (train: sampled from 2016, 2017, 2018, test: 2019)\n",
      "2025-11-27 07:37:48,159 - INFO - Memory usage [After MC-CV Split Creation]: 351.7 MB\n",
      "2025-11-27 07:37:48,159 - INFO - Running MC-CV analysis...\n",
      "2025-11-27 07:37:48,159 - INFO - Memory usage [Before MC-CV Execution]: 351.7 MB\n",
      "2025-11-27 07:37:48,242 - INFO - Skipping catboost: results already exist in S3 (s3://pgxdatalake/gold/feature_importance/opioid_ed/0-12/catboost_feature_importance.csv)\n",
      "2025-11-27 07:37:48,293 - INFO - Loaded existing catboost results from S3: 549 features\n",
      "2025-11-27 07:37:48,296 - INFO - Saved S3 results locally: 3_feature_importance/outputs/opioid_ed_0_12_catboost_feature_importance.csv\n",
      "2025-11-27 07:37:48,306 - INFO - Skipping random_forest: results already exist in S3 (s3://pgxdatalake/gold/feature_importance/opioid_ed/0-12/random_forest_feature_importance.csv)\n",
      "2025-11-27 07:37:48,348 - INFO - Loaded existing random_forest results from S3: 549 features\n",
      "2025-11-27 07:37:48,350 - INFO - Saved S3 results locally: 3_feature_importance/outputs/opioid_ed_0_12_random_forest_feature_importance.csv\n",
      "2025-11-27 07:37:48,362 - INFO - Skipping xgboost: results already exist in S3 (s3://pgxdatalake/gold/feature_importance/opioid_ed/0-12/xgboost_feature_importance.csv)\n",
      "2025-11-27 07:37:48,397 - INFO - Loaded existing xgboost results from S3: 549 features\n",
      "2025-11-27 07:37:48,400 - INFO - Saved S3 results locally: 3_feature_importance/outputs/opioid_ed_0_12_xgboost_feature_importance.csv\n",
      "2025-11-27 07:37:48,412 - INFO - Skipping xgboost_rf: results already exist in S3 (s3://pgxdatalake/gold/feature_importance/opioid_ed/0-12/xgboost_rf_feature_importance.csv)\n",
      "2025-11-27 07:37:48,485 - INFO - Loaded existing xgboost_rf results from S3: 549 features\n",
      "2025-11-27 07:37:48,488 - INFO - Saved S3 results locally: 3_feature_importance/outputs/opioid_ed_0_12_xgboost_rf_feature_importance.csv\n",
      "2025-11-27 07:37:48,501 - INFO - Skipping lightgbm: results already exist in S3 (s3://pgxdatalake/gold/feature_importance/opioid_ed/0-12/lightgbm_feature_importance.csv)\n",
      "2025-11-27 07:37:48,559 - INFO - Loaded existing lightgbm results from S3: 549 features\n",
      "2025-11-27 07:37:48,562 - INFO - Saved S3 results locally: 3_feature_importance/outputs/opioid_ed_0_12_lightgbm_feature_importance.csv\n",
      "2025-11-27 07:37:48,575 - INFO - Skipping extratrees: results already exist in S3 (s3://pgxdatalake/gold/feature_importance/opioid_ed/0-12/extratrees_feature_importance.csv)\n",
      "2025-11-27 07:37:48,625 - INFO - Loaded existing extratrees results from S3: 549 features\n",
      "2025-11-27 07:37:48,628 - INFO - Saved S3 results locally: 3_feature_importance/outputs/opioid_ed_0_12_extratrees_feature_importance.csv\n",
      "2025-11-27 07:37:48,639 - INFO - Skipping logistic_regression: results already exist in S3 (s3://pgxdatalake/gold/feature_importance/opioid_ed/0-12/logistic_regression_feature_importance.csv)\n",
      "2025-11-27 07:37:48,671 - INFO - Loaded existing logistic_regression results from S3: 549 features\n",
      "2025-11-27 07:37:48,674 - INFO - Saved S3 results locally: 3_feature_importance/outputs/opioid_ed_0_12_logistic_regression_feature_importance.csv\n",
      "2025-11-27 07:37:48,721 - INFO - Skipping linearsvc: results already exist in S3 (s3://pgxdatalake/gold/feature_importance/opioid_ed/0-12/linearsvc_feature_importance.csv)\n",
      "2025-11-27 07:37:48,758 - INFO - Loaded existing linearsvc results from S3: 549 features\n",
      "2025-11-27 07:37:48,761 - INFO - Saved S3 results locally: 3_feature_importance/outputs/opioid_ed_0_12_linearsvc_feature_importance.csv\n",
      "2025-11-27 07:37:48,775 - INFO - Skipping elasticnet: results already exist in S3 (s3://pgxdatalake/gold/feature_importance/opioid_ed/0-12/elasticnet_feature_importance.csv)\n",
      "2025-11-27 07:37:48,843 - INFO - Loaded existing elasticnet results from S3: 549 features\n",
      "2025-11-27 07:37:48,845 - INFO - Saved S3 results locally: 3_feature_importance/outputs/opioid_ed_0_12_elasticnet_feature_importance.csv\n",
      "2025-11-27 07:37:48,858 - INFO - Skipping lasso: results already exist in S3 (s3://pgxdatalake/gold/feature_importance/opioid_ed/0-12/lasso_feature_importance.csv)\n",
      "2025-11-27 07:37:48,897 - INFO - Loaded existing lasso results from S3: 549 features\n",
      "2025-11-27 07:37:48,900 - INFO - Saved S3 results locally: 3_feature_importance/outputs/opioid_ed_0_12_lasso_feature_importance.csv\n",
      "2025-11-27 07:37:48,900 - INFO - Memory usage [After MC-CV Execution]: 353.2 MB\n",
      "2025-11-27 07:37:48,900 - INFO - Aggregating results...\n",
      "2025-11-27 07:37:48,901 - INFO - Best model: linearsvc with recall=0.2177\n",
      "2025-11-27 07:37:48,920 - INFO - Saved aggregated results locally: 3_feature_importance/outputs/opioid_ed_0_12_aggregated_feature_importance.csv\n",
      "2025-11-27 07:37:48,965 - INFO - Uploaded aggregated results to S3: s3://pgxdatalake/gold/feature_importance/opioid_ed/0-12/aggregated_feature_importance.csv\n",
      "2025-11-27 07:37:48,965 - INFO - Saving logs to S3...\n",
      "\n",
      "[SUCCESS] Analysis complete!\n",
      "  Aggregated output: 3_feature_importance/outputs/opioid_ed_0_12_aggregated_feature_importance.csv\n",
      "  Features analyzed: N/A\n",
      "\n",
      "  Individual model results saved to: 3_feature_importance/outputs/\n",
      "  All results uploaded to: s3://pgxdatalake/gold/feature_importance/opioid_ed/0-12/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['/home/pgx3874/jupyter-env/bin/python3.11', '3_feature_importance/run_cohort_1_0_12.py'], returncode=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cohort 1, Age 0-12\n",
    "\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(\n",
    "    [str(PYTHON_BIN), \"3_feature_importance/run_cohort_1_0_12.py\"],\n",
    "    cwd=PROJECT_ROOT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort 1 – Age 13–24\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running feature importance for opioid_ed / 13-24\n",
      "2025-11-27 07:38:56,968 - INFO - ================================================================================\n",
      "2025-11-27 07:38:56,968 - INFO - FEATURE IMPORTANCE ANALYSIS - MONTE CARLO CROSS-VALIDATION\n",
      "2025-11-27 07:38:56,968 - INFO - ================================================================================\n",
      "2025-11-27 07:38:56,968 - INFO - Cohort: opioid_ed\n",
      "2025-11-27 07:38:56,968 - INFO - Age Band: 13-24\n",
      "2025-11-27 07:38:56,968 - INFO - Train Years: 2016, 2017, 2018\n",
      "2025-11-27 07:38:56,968 - INFO - Test Year: 2019\n",
      "2025-11-27 07:38:56,968 - INFO - MC-CV Splits: 200\n",
      "2025-11-27 07:38:56,968 - INFO - Scaling Metric: recall\n",
      "2025-11-27 07:38:56,968 - INFO - Debug Mode: Disabled\n",
      "2025-11-27 07:38:56,968 - INFO - ================================================================================\n",
      "2025-11-27 07:38:56,968 - INFO - Loading cohort data...\n",
      "2025-11-27 07:38:56,968 - INFO - Memory usage [Before Data Loading]: 336.0 MB\n",
      "2025-11-27 07:38:56,968 - INFO - Loading training data from years: 2016, 2017, 2018\n",
      "2025-11-27 07:38:57,133 - INFO - Loaded 236568 records from year 2016\n",
      "2025-11-27 07:38:57,215 - INFO - Loaded 116367 records from year 2017\n",
      "2025-11-27 07:38:57,275 - INFO - Loaded 83047 records from year 2018\n",
      "2025-11-27 07:38:57,323 - INFO - Combined training data: 435982 event-level records, 9834 unique patients\n",
      "2025-11-27 07:38:57,323 - INFO - Loading test data from year: 2019\n",
      "2025-11-27 07:38:57,452 - INFO - Test data: 176151 event-level records, 3840 unique patients\n",
      "2025-11-27 07:38:57,452 - INFO - Memory usage [After Data Loading]: 563.0 MB\n",
      "2025-11-27 07:38:57,452 - INFO - Creating patient-level features for training data...\n",
      "2025-11-27 07:38:58,079 - INFO - Creating patient-level features for test data...\n",
      "2025-11-27 07:38:58,318 - INFO - Total unique items across train and test: 12557\n",
      "2025-11-27 07:39:51,757 - INFO - Filtering constant features...\n",
      "2025-11-27 07:39:51,769 - INFO - Items in training data: 11058\n",
      "2025-11-27 07:39:51,773 - INFO - Items in test data: 6273\n",
      "2025-11-27 07:39:51,773 - INFO - Total items (train + test): 12557\n",
      "2025-11-27 07:39:51,774 - INFO - Sample training items: ['PREPARATION H', 'S52521A', 'M84361A', 'R739', 'S91352A']\n",
      "2025-11-27 07:39:53,151 - INFO - Item 'M84361A': nunique=2, sample values: {'': 9836, 'M84361A': 2}\n",
      "2025-11-27 07:39:53,361 - INFO - Item 'PREPARATION H': nunique=2, sample values: {'': 9836, 'PREPARATION H': 2}\n",
      "2025-11-27 07:39:53,441 - INFO - Item 'R739': nunique=2, sample values: {'': 9822, 'R739': 16}\n",
      "2025-11-27 07:39:53,575 - INFO - Item 'S52521A': nunique=2, sample values: {'': 9836, 'S52521A': 2}\n",
      "2025-11-27 07:39:53,720 - INFO - Item 'S91352A': nunique=2, sample values: {'': 9837, 'S91352A': 1}\n",
      "2025-11-27 07:39:53,963 - INFO - Removing 1499 constant features (out of 12557 total)\n",
      "2025-11-27 07:39:53,966 - INFO - Saved constant features list: 3_feature_importance/outputs/opioid_ed_13_24_constant_features.csv\n",
      "2025-11-27 07:39:54,032 - INFO - Uploaded constant features to S3: s3://pgxdatalake/gold/feature_importance/model_metadata/opioid_ed/13-24_constant_features.csv\n",
      "2025-11-27 07:39:55,575 - INFO - Feature engineering complete:\n",
      "2025-11-27 07:39:55,575 - INFO -   Training: 9838 patients, 11058 features\n",
      "2025-11-27 07:39:55,575 - INFO -   Test: 3839 patients, 11058 features\n",
      "2025-11-27 07:39:55,575 - INFO - Memory usage [After Feature Engineering]: 4239.3 MB\n",
      "2025-11-27 07:39:55,575 - INFO - Creating MC-CV splits (sampling from train years, testing on 2019)...\n",
      "2025-11-27 07:39:55,575 - INFO - Memory usage [Before MC-CV Split Creation]: 4239.3 MB\n",
      "2025-11-27 07:39:56,752 - INFO - Created 200 MC-CV splits (train: sampled from 2016, 2017, 2018, test: 2019)\n",
      "2025-11-27 07:39:56,752 - INFO - Memory usage [After MC-CV Split Creation]: 4239.6 MB\n",
      "2025-11-27 07:39:56,752 - INFO - Running MC-CV analysis...\n",
      "2025-11-27 07:39:56,752 - INFO - Memory usage [Before MC-CV Execution]: 4239.6 MB\n",
      "2025-11-27 07:39:56,769 - INFO - Skipping catboost: results already exist in S3 (s3://pgxdatalake/gold/feature_importance/opioid_ed/13-24/catboost_feature_importance.csv)\n",
      "2025-11-27 07:39:56,873 - INFO - Loaded existing catboost results from S3: 11058 features\n",
      "2025-11-27 07:39:56,920 - INFO - Saved S3 results locally: 3_feature_importance/outputs/opioid_ed_13_24_catboost_feature_importance.csv\n",
      "2025-11-27 07:39:56,933 - INFO - Running MC-CV for random_forest...\n",
      "2025-11-27 07:39:56,934 - INFO - Memory usage [Before MC-CV: random_forest]: 4239.6 MB\n",
      "\n",
      "--- Running MC-CV for random_forest (200 splits) ---\n"
     ]
    }
   ],
   "source": [
    "# Cohort 1, Age 13-24\n",
    "\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(\n",
    "    [str(PYTHON_BIN), \"3_feature_importance/run_cohort_1_13_24.py\"],\n",
    "    cwd=PROJECT_ROOT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort 1 – Age 25–44\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort 1, Age 25-44\n",
    "\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(\n",
    "    [str(PYTHON_BIN), \"3_feature_importance/run_cohort_1_25_44.py\"],\n",
    "    cwd=PROJECT_ROOT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort 1 – Age 45–54\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort 1, Age 45-54\n",
    "\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(\n",
    "    [str(PYTHON_BIN), \"3_feature_importance/run_cohort_1_45_54.py\"],\n",
    "    cwd=PROJECT_ROOT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort 1 – Age 55–64\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort 1, Age 55-64\n",
    "\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(\n",
    "    [str(PYTHON_BIN), \"3_feature_importance/run_cohort_1_55_64.py\"],\n",
    "    cwd=PROJECT_ROOT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort 1 – Age 65–74\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort 1, Age 65-74\n",
    "\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(\n",
    "    [str(PYTHON_BIN), \"3_feature_importance/run_cohort_1_65_74.py\"],\n",
    "    cwd=PROJECT_ROOT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort 1 – Age 75–84\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort 1, Age 75-84\n",
    "\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(\n",
    "    [str(PYTHON_BIN), \"3_feature_importance/run_cohort_1_75_84.py\"],\n",
    "    cwd=PROJECT_ROOT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort 1 – Age 85–94\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort 1, Age 85-94\n",
    "\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(\n",
    "    [str(PYTHON_BIN), \"3_feature_importance/run_cohort_1_85_94.py\"],\n",
    "    cwd=PROJECT_ROOT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort 1 – Age 95–114\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort 1, Age 95-114\n",
    "\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(\n",
    "    [str(PYTHON_BIN), \"3_feature_importance/run_cohort_1_95_114.py\"],\n",
    "    cwd=PROJECT_ROOT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort 2 – Age 0–12\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort 2, Age 0-12 (e.g., non-opioid_ed)\n",
    "\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(\n",
    "    [str(PYTHON_BIN), \"3_feature_importance/run_cohort_2_0_12.py\"],\n",
    "    cwd=PROJECT_ROOT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort 2 – Age 13–24\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort 2, Age 13-24\n",
    "\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(\n",
    "    [str(PYTHON_BIN), \"3_feature_importance/run_cohort_2_13_24.py\"],\n",
    "    cwd=PROJECT_ROOT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort 2 – Age 25–44\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort 2, Age 25-44\n",
    "\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(\n",
    "    [str(PYTHON_BIN), \"3_feature_importance/run_cohort_2_25_44.py\"],\n",
    "    cwd=PROJECT_ROOT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort 2 – Age 45–54\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort 2, Age 45-54\n",
    "\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(\n",
    "    [str(PYTHON_BIN), \"3_feature_importance/run_cohort_2_45_54.py\"],\n",
    "    cwd=PROJECT_ROOT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort 2 – Age 55–64\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort 2, Age 55-64\n",
    "\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(\n",
    "    [str(PYTHON_BIN), \"3_feature_importance/run_cohort_2_55_64.py\"],\n",
    "    cwd=PROJECT_ROOT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort 2 – Age 65–74\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort 2, Age 65-74\n",
    "\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(\n",
    "    [str(PYTHON_BIN), \"3_feature_importance/run_cohort_2_65_74.py\"],\n",
    "    cwd=PROJECT_ROOT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort 2 – Age 75–84\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort 2, Age 75-84\n",
    "\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(\n",
    "    [str(PYTHON_BIN), \"3_feature_importance/run_cohort_2_75_84.py\"],\n",
    "    cwd=PROJECT_ROOT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort 2 – Age 85–94\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort 2, Age 85-94\n",
    "\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(\n",
    "    [str(PYTHON_BIN), \"3_feature_importance/run_cohort_2_85_94.py\"],\n",
    "    cwd=PROJECT_ROOT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort 2 – Age 95–114\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort 2, Age 95-114\n",
    "\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(\n",
    "    [str(PYTHON_BIN), \"3_feature_importance/run_cohort_2_95_114.py\"],\n",
    "    cwd=PROJECT_ROOT,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run All Cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all cohort scripts sequentially\n",
    "# Each script is idempotent and will skip work if results already exist in S3.\n",
    "\n",
    "FAIL_FAST = True  # Stop on first failure; set to False to continue on errors\n",
    "\n",
    "for script in COHORT_SCRIPTS:\n",
    "    rel_path = script.relative_to(PROJECT_ROOT)\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Running cohort script: {rel_path}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    result = subprocess.run(\n",
    "        [str(PYTHON_BIN), str(rel_path)],\n",
    "        cwd=PROJECT_ROOT,\n",
    "    )\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        msg = f\"Script {rel_path} failed with exit code {result.returncode}\"\n",
    "        print(msg)\n",
    "        if FAIL_FAST:\n",
    "            raise RuntimeError(msg)\n",
    "\n",
    "print(\"\\nAll cohort scripts completed (or were skipped as already done).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sync Results and Code to S3\n",
    "\n",
    "Sync output files and code (notebook + R script) to S3 bucket. \n",
    "- Outputs: CSV results files\n",
    "- Code: Notebook and R script for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Sync outputs and code to S3\n",
    "# On EC2, we're in the feature_importance directory  \n",
    "s3_bucket <- \"s3://pgx-repository/pgx-analysis/3_feature_importance/\"\n",
    "\n",
    "# Find AWS CLI (check common locations - EC2 typically has it in /usr/local/bin or /usr/bin)\n",
    "aws_cmd <- Sys.which(\"aws\")\n",
    "if (aws_cmd == \"\") {\n",
    "  # Try common EC2 installation paths\n",
    "  aws_paths <- c(\n",
    "    \"/usr/local/bin/aws\",\n",
    "    \"/usr/bin/aws\",\n",
    "    \"/home/ec2-user/.local/bin/aws\"\n",
    "  )\n",
    "  aws_cmd <- NULL\n",
    "  for (path in aws_paths) {\n",
    "    if (file.exists(path)) {\n",
    "      aws_cmd <- path\n",
    "      break\n",
    "    }\n",
    "  }\n",
    "  if (is.null(aws_cmd)) {\n",
    "    stop(\"AWS CLI not found. Please install AWS CLI or ensure it's in your PATH.\")\n",
    "  }\n",
    "}\n",
    "\n",
    "cat(\"Syncing outputs and code to S3...\\n\")\n",
    "cat(\"Source: feature_importance/ directory\\n\")\n",
    "cat(\"Destination:\", s3_bucket, \"\\n\")\n",
    "cat(\"AWS CLI:\", aws_cmd, \"\\n\\n\")\n",
    "\n",
    "# Get current directory (should be feature_importance)\n",
    "current_dir <- getwd()\n",
    "if (!grepl(\"feature_importance\", current_dir)) {\n",
    "  warning(\"Current directory doesn't appear to be feature_importance. Double-check sync destination.\")\n",
    "}\n",
    "\n",
    "# Sync feature_importance directory (includes outputs/ and code files)\n",
    "# Explicitly include notebook, R scripts, README files, and outputs directory\n",
    "# Exclude temporary files, checkpoints, and unnecessary directories\n",
    "# Note: --delete flag removed for safety (won't delete files in S3 that don't exist locally)\n",
    "# Include patterns are processed before exclude patterns, then exclude everything else\n",
    "sync_cmd <- sprintf(\n",
    "  '\"%s\" s3 sync \"%s\" %s --include \"*.ipynb\" --include \"*.R\" --include \"README*.md\" --include \"outputs/**\" --exclude \"*checkpoint*\" --exclude \"*.tmp\" --exclude \"*.ipynb_checkpoints/*\" --exclude \"*.RData\" --exclude \"*.Rhistory\" --exclude \".Rproj.user/*\" --exclude \"catboost_info/*\" --exclude \"*.log\" --exclude \"*\"',\n",
    "  aws_cmd,\n",
    "  current_dir,\n",
    "  s3_bucket\n",
    ")\n",
    "\n",
    "cat(\"Running:\", sync_cmd, \"\\n\\n\")\n",
    "result <- system(sync_cmd)\n",
    "\n",
    "if (result == 0) {\n",
    "  cat(\"✓ Successfully synced outputs and code to S3\\n\")\n",
    "  cat(\"  - Outputs:\", file.path(output_dir), \"\\n\")\n",
    "  cat(\"  - Code: *.ipynb, *.R, README*.md\\n\")\n",
    "} else {\n",
    "  warning(sprintf(\"S3 sync returned exit code %d. Check AWS credentials and permissions.\", result))\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# SAVE LOGS TO S3 (aligned with 2_create_cohort)\n",
    "# ============================================================\n",
    "cat(\"\\n========================================\\n\")\n",
    "cat(\"Saving logs to S3...\\n\")\n",
    "cat(\"========================================\\n\")\n",
    "\n",
    "# Close log file connection\n",
    "if (exists(\"log_setup\") && !is.null(log_setup$log_connection)) {\n",
    "  if (isOpen(log_setup$log_connection)) {\n",
    "    close(log_setup$log_connection)\n",
    "  }\n",
    "}\n",
    "\n",
    "# Save logs to S3\n",
    "if (exists(\"logger\") && exists(\"log_file_path\")) {\n",
    "  tryCatch({\n",
    "    s3_path <- save_logs_to_s3_r(log_file_path, COHORT_NAME, AGE_BAND, EVENT_YEAR, logger)\n",
    "    if (!is.null(s3_path)) {\n",
    "      logger$info(\"✓ Analysis completed successfully. Logs saved to S3.\")\n",
    "    }\n",
    "  }, error = function(e) {\n",
    "    cat(sprintf(\"Warning: Could not save logs to S3: %s\\n\", e$message))\n",
    "    cat(sprintf(\"Log file saved locally: %s\\n\", log_file_path))\n",
    "  })\n",
    "} else {\n",
    "  cat(\"Warning: Logger not initialized. Logs not saved to S3.\\n\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shutdown EC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Shutdown EC2 instance after analysis completes\n",
    "# Set SHUTDOWN_EC2 = TRUE to enable, FALSE to disable\n",
    "SHUTDOWN_EC2 <- TRUE  # Change to TRUE to enable auto-shutdown\n",
    "\n",
    "if (SHUTDOWN_EC2) {\n",
    "  cat(\"\\n========================================\\n\")\n",
    "  cat(\"Shutting down EC2 instance...\\n\")\n",
    "  cat(\"========================================\\n\")\n",
    "  \n",
    "  # Get instance ID from EC2 metadata service\n",
    "  instance_id <- tryCatch({\n",
    "    system(\"curl -s http://169.254.169.254/latest/meta-data/instance-id\", intern = TRUE)\n",
    "  }, error = function(e) {\n",
    "    cat(\"Warning: Could not retrieve instance ID from metadata service.\\n\")\n",
    "    cat(\"If running on EC2, check that metadata service is accessible.\\n\")\n",
    "    return(NULL)\n",
    "  })\n",
    "  \n",
    "  if (!is.null(instance_id) && length(instance_id) > 0 && nchar(instance_id[1]) > 0) {\n",
    "    instance_id <- instance_id[1]\n",
    "    cat(sprintf(\"Instance ID: %s\\n\", instance_id))\n",
    "    \n",
    "    # Find AWS CLI\n",
    "    aws_cmd <- Sys.which(\"aws\")\n",
    "    if (aws_cmd == \"\") {\n",
    "      aws_paths <- c(\n",
    "        \"/usr/local/bin/aws\",\n",
    "        \"/usr/bin/aws\",\n",
    "        \"/home/ec2-user/.local/bin/aws\"\n",
    "      )\n",
    "      aws_cmd <- NULL\n",
    "      for (path in aws_paths) {\n",
    "        if (file.exists(path)) {\n",
    "          aws_cmd <- path\n",
    "          break\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    if (!is.null(aws_cmd) && aws_cmd != \"\") {\n",
    "      # Stop the instance (use terminate-instances for permanent deletion)\n",
    "      shutdown_cmd <- sprintf(\n",
    "        '\"%s\" ec2 stop-instances --instance-ids %s',\n",
    "        aws_cmd,\n",
    "        instance_id\n",
    "      )\n",
    "      \n",
    "      cat(\"Running:\", shutdown_cmd, \"\\n\")\n",
    "      result <- system(shutdown_cmd)\n",
    "      \n",
    "      if (result == 0) {\n",
    "        cat(\"✓ EC2 instance stop command sent successfully\\n\")\n",
    "        cat(\"Instance will stop in a few moments.\\n\")\n",
    "        cat(\"Note: This is a STOP (not terminate), so you can restart it later.\\n\")\n",
    "      } else {\n",
    "        warning(sprintf(\"EC2 stop command returned exit code %d. Check AWS credentials and permissions.\", result))\n",
    "      }\n",
    "    } else {\n",
    "      cat(\"Warning: AWS CLI not found. Cannot shutdown instance.\\n\")\n",
    "      cat(\"Install AWS CLI or ensure it's in your PATH.\\n\")\n",
    "    }\n",
    "  } else {\n",
    "    cat(\"Warning: Could not determine instance ID. Skipping shutdown.\\n\")\n",
    "    cat(\"If you want to shutdown manually, use:\\n\")\n",
    "    cat(\"  aws ec2 stop-instances --instance-ids <your-instance-id>\\n\")\n",
    "  }\n",
    "} else {\n",
    "  cat(\"\\n========================================\\n\")\n",
    "  cat(\"EC2 Auto-Shutdown: DISABLED\\n\")\n",
    "  cat(\"========================================\\n\")\n",
    "  cat(\"To enable auto-shutdown, set SHUTDOWN_EC2 = TRUE in this cell.\\n\")\n",
    "  cat(\"Instance will continue running.\\n\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
